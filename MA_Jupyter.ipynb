{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Code for Master's Thesis: Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Questions\n",
    "\n",
    "1. Welche Themen können mithilfe von Topic Modeling aus den DHd-Abstracts\n",
    "der Tagungen zwischen 2014 und 2023 gefunden werden?\n",
    "\n",
    "2. Welche Themen kommen häufig gemeinsam in einem Dokument vor und weisen\n",
    "daher eine hohe Themenähnlichkeit (topic similarity) auf?\n",
    "\n",
    "3. Wie haben sich die Themenschwerpunkte im Verlauf der Jahre verändert -\n",
    "welche Trends sind zu erkennen?\n",
    "\n",
    "4. Welche Entwicklungen sind in Bezug auf die Verwendung verschiedener Forschungsmethoden festzustellen?\n",
    "\n",
    "5. Welche Personen sind besonders häufig mit Abstracts vertreten, in welchen\n",
    "Autor:innenteams treten sie auf und wie verändern sich diese im Zeitverlauf?\n",
    "\n",
    "6. Welche Personencluster sind in Bezug auf die Themenschwerpunkte zu erkennen und wie verändern sich diese?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Reading in necessary pdf- and xml-files\n",
    "import zipfile\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "from io import BytesIO\n",
    "\n",
    "#(pre)processing the files\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import spacy\n",
    "from langdetect import detect\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "#LDA\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "#Evaluation\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#Visualisation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing function: eliminating non-German texts from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    \n",
    "    #gets text as input\n",
    "    lang = detect(text)\n",
    "\n",
    "    #returns the language tag of detected language\n",
    "    return lang        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing function: cleaning the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:19: DeprecationWarning: invalid escape sequence '\\,'\n",
      "<>:19: DeprecationWarning: invalid escape sequence '\\,'\n",
      "C:\\Windows\\Temp\\ipykernel_4568\\4163839780.py:19: DeprecationWarning: invalid escape sequence '\\,'\n",
      "  punctuation = '''!“()´`¨[]{};:'\"\\,<>./?@#$%^&*_~'''\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    # lowering text case\n",
    "    # clean = text.lower()\n",
    "    \n",
    "    #filtering weblinks\n",
    "    clean = re.sub('http(.*?) ', '', str(text))\n",
    "    \n",
    "    # filtering numbers\n",
    "    clean = re.sub(r'\\d', '', clean)\n",
    "    \n",
    "    # filtering paragraphs\n",
    "    clean = re.sub(r'\\n', '', clean)\n",
    "    \n",
    "    # filtering markup from XML\n",
    "    clean = re.sub(r'<(.*?)>', '', clean)\n",
    "\n",
    "    # filtering punctuation\n",
    "    punctuation = '''!“()´`¨[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    for word in clean:\n",
    "        if word in punctuation:\n",
    "            clean = clean.replace(word, \"\")\n",
    "            \n",
    "    \n",
    "    # filtering abbreviations\n",
    "    clean = re.sub('bspw', '', clean)\n",
    "    clean = re.sub('sog', '', clean)\n",
    "    clean = re.sub('zb', '', clean)\n",
    "    clean = re.sub('ua', '', clean)\n",
    "    clean = re.sub('vgl', '', clean)\n",
    "\n",
    "    return clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessig function: PDF-specific cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_specific_clean(text):\n",
    "    \n",
    "    # processing German Umlaute correctly\n",
    "    clean = re.sub(\" ¨a\", \"ä\", text)\n",
    "    clean = re.sub(\" ¨u\", \"ü\", clean)\n",
    "    clean = re.sub(\" ¨o\", \"ö\", clean)\n",
    "    clean = re.sub(\"¨a\", \"ä\", clean)\n",
    "    clean = re.sub(\"¨u\", \"ü\", clean)\n",
    "    clean = re.sub(\"¨o\", \"ö\", clean)\n",
    "    \n",
    "    # PDF-specific substitution\n",
    "    clean = re.sub(\"”\", \" \", clean)\n",
    "    #clean = re.sub(\"-\", \"\", clean)\n",
    "\n",
    "    # return cleaned-up text\n",
    "    return clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing function: removing stopwords and very short/long words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \n",
    "    # import German stopword list \n",
    "    stops = set(stopwords.words(\"german\"))\n",
    "    \n",
    "    # convert a document into a list of lowercase tokens, ignoring tokens that are too short or too long, no deaccentation (by default)\n",
    "    words = gensim.utils.simple_preprocess(text)\n",
    "    \n",
    "    # filter stopwords\n",
    "    words_filtered = []\n",
    "    for w in words:\n",
    "        if w not in stops:\n",
    "            words_filtered.append(w)\n",
    "    \n",
    "    # return list of words that are NOT stopwords\n",
    "    return words_filtered\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing function: (morpho-syntactic) lemmatization\n",
    "Hint: 'de_core_news_md' model has to be downloaded via pip beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(texts):\n",
    "    \n",
    "    # only words tagged as nouns, verbs, adjectives and adverbs should be considered\n",
    "    allowed_tags = ['NOUN', 'VERB', 'ADJ', 'ADV']\n",
    "\n",
    "    # disabling parser and ner-tool to accelerate computing \n",
    "    nlp = spacy.load('de_core_news_md', disable=['parser', 'ner'])\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_tags:\n",
    "                new_text.append(token.lemma_.lower())\n",
    "        # delete all empty sets where the pos-tag was not in allowed list\n",
    "        if new_text != []:        \n",
    "            final = \" \".join(new_text)\n",
    "            texts_out.append(final)\n",
    "    \n",
    "    # return list of lemmatized words\n",
    "    return (texts_out)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: Extracting Keywords from XML-File\n",
    "- extracts tags \\<keywords n=\"topics\" scheme=\"ConfTool\"> and \\<keywords n=\"keywords\" scheme=\"ConfTool\"> to get keywords of the texts\n",
    "- checks validity of keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(xmldata):\n",
    "    \n",
    "    # finds all tags <keywords n=\"keywords\"> and <keywords n=\"topics\">, removes all tags within\n",
    "    keywords = str(soup.find_all(\"keywords\", {\"n\": (\"keywords\", \"topics\")}))\n",
    "    keywords = re.sub(\"<(.*?)>\", \"\", keywords)\n",
    "    keywords = keywords.split(\"\\n\")\n",
    "\n",
    "    # filters keywords shorter than 2 letters\n",
    "    for item in keywords:\n",
    "        if len(item) <= 2 and item in keywords:\n",
    "            keywords.remove(item)\n",
    "            \n",
    "    # returns list\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: Counting number of extracted keywords\n",
    "- function creates dictionary from the list of keywords\n",
    "- counts how often each method is used\n",
    "- returns the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_methods(keywords, methods_dict):\n",
    "    \n",
    "    # for each item in keyword list, check if it is alredy in dictionary\n",
    "    # if not, add and set count to 1, if yes add +1 to count\n",
    "    for item in keywords:\n",
    "        if item not in methods_dict.keys():\n",
    "            methods_dict[item] = 1\n",
    "        else:\n",
    "            methods_dict[item] += 1\n",
    "    # sort dictionary according to highest count in the values\n",
    "    sorted_dict = sorted(methods_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # return the sorted dictionary\n",
    "    return sorted_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: Extracting the author names\n",
    "Extracts the names of the authors and returns a list of lists containing the names of the single texts' authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_authors(all_authors, title_stmt):\n",
    "    \n",
    "    # navigating to the title statement and finding all tags <author>\n",
    "    authors = title_stmt.find_all(\"author\")\n",
    "    fore_and_surnames = []\n",
    "    \n",
    "    # extracting the <surname> and <forename> tags and cleaning the outcome from the tags and the brackets\n",
    "    for element in authors:\n",
    "        names = element.find_all(['surname', 'forename'])\n",
    "        names =  re.sub(\"<(.*?)>\", \"\", str(names))\n",
    "        names = re.sub(\"</(.*?)>\", \"\", str(names))\n",
    "        names = re.sub(r'\\]', \"\", names)\n",
    "        names = re.sub(r'\\[', \"\", names)\n",
    "        fore_and_surnames.append(names)\n",
    "    all_authors.append(fore_and_surnames)\n",
    "    \n",
    "    return all_authors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: Extracting text from XML-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_xml_text(soup):\n",
    "    \n",
    "    # extract <p> tags from body of xml-document to find the actual text \n",
    "    document_body = soup.body\n",
    "    p_tags = document_body.find_all(\"p\")\n",
    "    \n",
    "    # return the text from p-tags\n",
    "    return p_tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions: Making bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts, bigram):\n",
    "    return([bigram[doc] for doc in texts])\n",
    "\n",
    "def make_trigrams(texts, trigram,bigram):\n",
    "    return ([trigram[bigram[doc]] for doc in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigrams_trigrams(texts):\n",
    "    \n",
    "    \"\"\" ADJUST MIN COUNT!! \"\"\"\n",
    "    bigram_phrases = gensim.models.Phrases(texts, min_count=2, threshold=100)\n",
    "    trigram_phrases = gensim.models.Phrases(bigram_phrases[texts], threshold=100)\n",
    "\n",
    "    bigram = gensim.models.phrases.Phraser(bigram_phrases)\n",
    "    trigram = gensim.models.phrases.Phraser(trigram_phrases)\n",
    "\n",
    "    data_bigrams = make_bigrams(texts, bigram)\n",
    "    data_bigrams_trigrams = make_trigrams(data_bigrams, trigram, bigram)\n",
    "\n",
    "    return data_bigrams_trigrams"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: Creating bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bow(data_words): \n",
    "    \n",
    "    # mapping the documents' words to a dictionary   \n",
    "    id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "    # creating a bag of words by using index of dictionary\n",
    "    bag_of_words_corpus = []\n",
    "    for text in data_words:\n",
    "        new = id2word.doc2bow(text)\n",
    "        bag_of_words_corpus.append(new)\n",
    "\n",
    "    # returning id2word-reference as well as bag of word itself, both needed for LDA    \n",
    "    return id2word, bag_of_words_corpus\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: TF-IDF weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(id2word, texts):\n",
    "    # simple bow for each document, containing tuples with (index, number of appearances of the word in the document)\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    # calculates term frequency (TF) weighted by the inverse document frequency (IDF) for every word/index in the bag of words\n",
    "    tfidf = TfidfModel(corpus, id2word=id2word)\n",
    "\n",
    "    # low_value as threshold\n",
    "    low_value = 0.03\n",
    "    words  = []\n",
    "    words_missing_in_tfidf = []\n",
    "\n",
    "    # for every single bag of words\n",
    "    for i in range(0, len(corpus)):\n",
    "        # consider each bow for each document\n",
    "        bow = corpus[i]\n",
    "        low_value_words = [] #reinitialize to be safe. You can skip this.\n",
    "        \n",
    "        # for each tuple (index, tfidf-value) in the bag of words, extract index (tfidf_ids)\n",
    "        tfidf_ids = [id for id, value in tfidf[bow]]\n",
    "        \n",
    "        # for each tuple (index, bow-value without tfidf), extract index\n",
    "        bow_ids = [id for id, value in bow]\n",
    "        \n",
    "        # if the value in the (index, tfidf-value) tuple is lower than 0.03, put id into list low_value_words\n",
    "        low_value_words = [id for id, value in tfidf[bow] if value < low_value]\n",
    "        \n",
    "        drops = low_value_words+words_missing_in_tfidf\n",
    "        \n",
    "        # which words will be deleted from the bow?\n",
    "        for item in drops:\n",
    "            words.append(id2word[item])\n",
    "    \n",
    "        words_missing_in_tfidf = [id for id in bow_ids if id not in tfidf_ids] # The words with tf-idf score 0 will be missing\n",
    "        \n",
    "        # add words which indexes are not in low_value_words and not in words_missing_in_tfidf to the new bag of words \n",
    "        new_bow = [b for b in bow if b[0] not in low_value_words and b[0] not in words_missing_in_tfidf]\n",
    "        \n",
    "        # new bow is missing certain indexes\n",
    "        corpus[i] = new_bow\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in zip-files of DHd-conferences (where only PDF-files are accessible) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['Testfile-pdf.zip']\n",
    "#filenames = ['DHd_2014.zip', 'DHd_2015.zip']\n",
    "\n",
    "all_pdf_texts = []\n",
    "for conference_file in filenames:\n",
    "    archive = zipfile.ZipFile(conference_file, 'r')\n",
    "    for name in archive.namelist():\n",
    "        if name[-4:] == '.pdf':\n",
    "            # Reading the PDF-files from the zip-archive            \n",
    "            PDF_read = PyPDF2.PdfReader(BytesIO(archive.read(name)))\n",
    "            # using doc_length to iterate over all pages of each abstract, using doc_text to generate one list of words per abstract (not one per page)\n",
    "            doc_length = len(PDF_read.pages)\n",
    "            doc_text = \" \"\n",
    "            for i in range(doc_length):\n",
    "                page_text = PDF_read.pages[i]\n",
    "                page_text = page_text.extract_text()\n",
    "                doc_text = str(doc_text) + str(page_text)\n",
    "            doc_text = pdf_specific_clean(doc_text)\n",
    "            all_pdf_texts.append(doc_text)\n",
    "\n",
    "                \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the zip-files of the DHd-Conferences (where XML-files were published)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['Testfile-xml.zip']\n",
    "# filenames = ['DHd_2016.zip', 'DHd_2017.zip', 'DHd_2018.zip', 'DHd_2019.zip', 'DHd_2020.zip',\n",
    "#              'DHd_2022.zip', 'DHd_2023.zip',]\n",
    "\n",
    "all_xml_files = []\n",
    "for conference_file in filenames:\n",
    "    archive = zipfile.ZipFile(conference_file, 'r')\n",
    "    # read in all files in the zip-file and check that they are xml-files\n",
    "    for name in archive.namelist():\n",
    "        if name[-4:] == '.xml' and not name[-9:] == 'final.xml':\n",
    "            all_xml_files.append(archive.read(name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XML-Files: Extracting the keywords given in the metadata of the abstracts in order to find the scientific methods used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Wissik, Tanja', 'Krek, Simon', 'Jakubicek, Milos', 'Tiberius, Carole', 'Navigli, Roberto', 'McCrae, John', 'Tasovac, Toma', 'Varadi, Tamas', 'Koeva, Svetla', 'Costa, Rute', 'Kernerman, Ilan', 'Monachini, Monica', 'Trap-Jensen, Lars', 'Pedersen, Bolette S.', 'Hildenbrandt, Vera', 'Kallas, Jelena', 'Porta-Zamorano, Jordi'], ['Wissik, Tanja', 'Resch, Claudia'], ['Zirker, Angelika'], ['Zirker, Angelika', 'Bauer, Matthias', 'Kirchhoff, Leonie', 'Lahrsow, Miriam']]\n"
     ]
    }
   ],
   "source": [
    "# Creating dictionary to count how often each method is used\n",
    "methods_dict = {}\n",
    "all_xml_texts = []\n",
    "author_names = []\n",
    "\n",
    "for item in all_xml_files:\n",
    "    \n",
    "    soup = BeautifulSoup(item, 'xml')\n",
    "    \n",
    "    \"\"\"Code for extracting the keywords used in xml-files\"\"\"\n",
    "    \n",
    "    keywords = extract_keywords(soup)\n",
    "    methods_used = count_methods(keywords, methods_dict)\n",
    "    # print(\"methods used\", methods_used)\n",
    "    \n",
    "    \n",
    "    \"\"\"Code for extracting the actual text from xml-files\"\"\"\n",
    "    \n",
    "    xml_text = extract_xml_text(soup)\n",
    "    all_xml_texts.append(xml_text)\n",
    "\n",
    "\n",
    "    \"\"\"Code for extracting the author names\"\"\"\n",
    "\n",
    "    # extract author names\n",
    "    title_stmt = soup.titleStmt\n",
    "    authors = extract_authors(author_names, title_stmt)\n",
    "print(authors) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the PDF texts and the XML texts for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_texts = all_pdf_texts + all_xml_texts\n",
    "list_all_texts = []\n",
    "for text in whole_texts:\n",
    "    lang = detect_language(str(text))\n",
    "    if lang == 'de':\n",
    "        text_item = clean_text(text)\n",
    "        text_item = remove_stopwords(text_item)\n",
    "        ''' EVTL Prozess nur einmal, damit nicht so lange '''\n",
    "        text_item = lemmatization(text_item)\n",
    "        list_all_texts.append(text_item)\n",
    "    else:\n",
    "        next"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['jahrestagung', 'digital', 'raum', 'vortrag', 'vortrag', 'diskussiontitel', 'frauenfrag', 'gegenstand', 'ntrovers', 'kommunika', 'tion', 'umkreis', 'erster', 'frauenbewegung', 'ressource', 'tersuchung', 'wolffstiftung', 'archiv', 'deutsch', 'kasseltel', 'kasseldekerstin', 'historikerin', 'arbeitsschw', 'erpunkt', 'liegen', 'bereichen', 'schen', 'frauenforschung', 'erforschung', 'r', 'frauenbewegung', 'leiten', 'stiftung', 'archiv', 'deutsch', 'geykenberlin', 'akademie', 'wissenschaft', 'digital', 'wörterbuch', 'deutsch', 'berlintel', 'geyk', 'arbeitsstellen', 'dwds', 'bbaw', 'liegen', 'bereichen', 'lexikographie', 'puslinguistik', 'gloninginstitut', 'istik', 'jlu', 'gießenotto', 'straße', 'gießentel', 'giessendethomas', 'ermanistik', 'fachlich', 'bereichen', 'textanalyse', 'semantik', 'ganisation', 'geschich', 'hinaus', 'digital', 'text', 'nutzung', 'infrastruktur', 'anwendbar', 'keit', 'reichweiten', 'digital', 'ressource', 'gegenstand', 'kommunikation', 'umkreis', 'sten', 'frauenbewegung', 'digital', 'ressource', 'untersuchung', 'ergeb', 'verbessern', 'zuordnung', 'thematisch', 'schwerpunkten', 'bestimmen', 'überg', 'reifend', 'netz', 'darstellung', 'präs', 'entation', 'ergebnis', 'nutzen', 'ergebnis', 'struktur', 'integrieren', 'problem', 'markup', 'spezifisch', 'fachlich', 'integriert', 'digital', 'mentation', 'anwendung', 'digital', 'aspekte', 'digital', 'verfahren', 'thematisch', 'beschreibung', 'themasda', 'folgend', 'beschrieben', 'thema', 'stehen', 'ganz', 'klasse', 'thematisch', 'fragestellung', 'jeweils', 'darauf', 'zogen', 'istdamit', 'fall', 'rderung', 'jekte', 'datenmanagemen', 'tmethode', 'digital', 'stellen', 'gegenstand', 'text', 'erster_ng', 'beginnend', 'jahrhundert', 'ihremkern', 'kommunikative', 'bewegung', 'zentral', 'streitpunken', 'forderung', 'hoch', 'phase', 'erster_ng', 'betreffen', 'bereich', 'politisch', 'zipation', 'wahlrecht', 'bildung', 'wesen', 'hochschulzug', 'beruflich', 'it', 'gerecht', 'lohn', 'almoral', 'prostituti', 'streit', 'punkt', 'forderung', 'öffe', 'ntlich', 'raum', 'thematisie', 'bedienen', 'vertreterinn', 'frauenbewegung', 'eigen', 'zeitschrift', 'petition', 'flugschrift', 'monographien', 'legen', 'tiv', 'hoffnung', 'forderung', 'argumente', 'versuchen', 'gesellschaft', 'vonder', 'notwendigkeit', 'veränderung', 'thema', 'erster', 'frauenbewegung', 'sozial', 'idee', 'geschichtlich', 'grundzüge', 'gut', 'erforschen', 'gelten', 'umfassend', 'tailliert', 'untersuchung', 'öffentlich', 'frauenfragend', 'beginnend', 'jahrhundert', 'bisher', 'desiderat', 'fachlich', 'frageste', 'llunge', 'systematisch', 'analyse', 'kommunikativ', 'struktur', 'musssich', 'linie', 'teilfrage', 'ehe', 'schnittpunkt', 'historisch', 'kursanalyse', 'historisch', 'chung', 'historisch', 'lexikologie', 'mantik', 'verorten', 'beantwortung', 'frage', 'gleichzeitig', 'beitrag', 'zurbislang', 'geschriebenen', 'r', 'frauenbewegung', 'undein', 'beitrag', 'geschichte', 'frau', 'lassen', 'einzeln', 'thematisch', 'diskursive', 'sträng', 'rekonstruieren', 'einzeltexte', 'gehören', 'jeweils', 'stimmen', 'diskursive', 'strang', 'tertextuelle', 'bezug', 'einze', 'ltexte', 'teilen', 'einzeltext', 'erkenn', 'bar', 'sprachlich', 'verfahren', 'ablieren', 'autorinn', 'bezug', 'ander', 'text', 'stützung', 'eigen', 'position', 'beispiel', 'fürgegnerisch', 'positione', 'anführen', 'zentral', 'etablierung', 'bestimmt', 'sicht', 'weisen', 'brauchen', 'sichtweise', 'undforderung', 'stützen', 'lässen', 'wortgebrauch', 'text', 'spezifisch', 'dokumentieren', 'teilfra', 'wortgebrauch', 'form', 'wortgebr', 'sichtweise', 'konstituier', 'forderung', 'ützen', 'zen', 'umsetzung', 'verhindern', 'funktion', 'orga', 'nisation', 'text', 'unterscheiden', 'xikalisch', 'text', 'frau', 'enfragen', 'diskurs', 'umkreis', 'text', 'domäne', 'rolle', 'digital', 'rkzeuge', 'verfahren', 'fachlich', 'werkzeug', 'verfahren', 'spielen', 'wesentlich', 'rolle', 'analyse', 'bearbeit', 'gestellung', 'integriert', 'präsentation', 'quellentexen', 'derdarstellung', 'analyse', 'ergebnissei', 'digital', 'werkzeug', 'verfahren', 'rolle', 'rahmen', 'vorarbeien', 'sehen', 'erster', 'quellentexen', 'volltexte', 'fassen', 'gemäß', 'richtlini', 'text', 'initiative', 'bereiten', 'genau', 'gemäß', 'basisformat', 'best', 'format', 'präsentation', 'historisch', 'text', 'infrastr', 'ukturprojekt', 'clarin', 'dtaq', 'bereich', 'deutsch', 'akademie', 'senschaft', 'clarin', 'artner', 'zielen', 'andardisierung', 'tigkeit', 'frei', 'verpflichten', 'digital', 'ressource', 'bereic', 'untersuchung', 'bislang', 'liniefür', 'zweck', 'lexikalisch', 'analyse', 'geringer', 'umfang', 'zweck', 'deranalyse', 'eingesetztii', 'integriert', 'ital', 'vorarbeien', 'konzeptionelle', 'überlegung', 'typ', 'säule', 'beruhta', 'darstellung', 'wortgebrauch', 'monographischer', 'formb', 'strukturiert', 'digital', 'textcorpora', 'spezifisch', 'diskursb', 'ereich', 'erweiterbar', 'digital', 'system', 'systematisch', 'textcorpora', 'beziehen', 'sy', 'stem', 'dieeinzeln', 'zentral', 'sdrücke', 'lexikographisch', 'beschreiben', 'undauf', 'textuell', 'gebrauch', 'beziehen', 'position', 'deskriptoren', 'markieren', 'thematisch', 'funktional', 'penspezifisch', 'usw', 'erschließung', 'ermöglichen', 'wirdein', 'wesentlich', 'zielsetzung', 'lexikalisch', 'dokumenta', 'tion', 'tate', 'befund', 'anzubinden', 'laufen', 'nde', 'dwds', 'eigen', 'vorarbeien', 'bisherig', 'vorarbeien', 'geplant', 'vortra', 'gehören', 'insbesondere', 'land', 'geförd', 'ert', 'projekt', 'inzwischen', 'abgeschlossen', 'magisterarbeit', 'thematisie', 'rungspraktik', 'wortgebrauch', 'diskurs', 'laufender', 'wort', 'gebrauch', 'imdiskurs', 'frauenwahlrechen', 'gegenstand', 'arbeit', 'thematisch', 'digital', 'nutaren', 'tieren', 'erschlossenen', 'glossar', 'integration', 'digital', 'volltexn', 'themenbereich', 'frauenfrag', 'dasdeutschen', 'rahmen', 'clarin', 'ausarbeitung', 'tlich', 'sprachgeschicht', 'lich', 'fallstudie', 'prototyp', 'lexikalisch', 'dokumentation', 'menbereich', 'resultat', 'gebotener', 'berichten', 'historisch', 'sprechen', 'kommunika', 'rortung', 'themas', 'bisherig', 'fachlich', 'resultat', 'bereichen', 'wortsc', 'uchung', 'bisherig', 'resultat', 'erfahrung', 'bereich', 'anwendung', 'digital', 'source', 'bereic', 'lexikalisch', 'erschließung', 'vonkorpustexen', 'organisation', 'thematisch', 'iskursiv', 'orientiert', 'lexikalisch', 'integration', 'sdarstellung', 'korpustext', 'sch', 'dokumentation', 'problemzon', 'nutzung', 'digital', 'ressource', 'diskurs', 'untersuchung', 'planung', 'struktur', 'vortragsd', 'vortrag', 'wesentlich', 'teil', 'einführung', 'erster_ng', 'chtliche', 'rolle', 'digital', 'ressource', 'analyse', 'gedrängter', 'überblick', 'bisherig', 'resultat', 'mittelpunkt', 'nächster', 'schritt', 'offen', 'stehen', 'bereichen', 'zusammenspiel', 'fachlich', 'ndung', 'methode', 'zuordnen', 'lassen', 'vorstellung', 'konzept', 'integriert', 'vernetzt', 'digital', 'säule', 'beruhen', 'monographisch', 'darstellung', 'digital', 'text', 'lexikalisch', 'dokumentation', 'verfahren', 'auszeichnung', 'auswertung', 'digital', 'korpustexte', 'hinblickauf', 'argumenta', 'tionsforme', 'bereich', 'gehören', 'relevant', 'textteilen', 'ganz', 'erschiedlicher', 'größesein', 'untersch', 'iedliche', 'parameter', 'lappend', 'führen', 'digital', 'unterstützung', 'lexikalisch', 'lexikologischer', 'analyse', 'korpustext', 'zusammengefasst', 'beitrag', 'exemplarisch', 'zeigen', 'verfahren', 'fachlich', 'fragestellung', 'bereichen', 'undsprach', 'eschichen', 'aufweisen', 'aufw', 'eisen', 'bisher', 'erfahren', 'problemzon', 'thematisieren'], ['religion', 'einsatz', 'analyse', 'institut', 'europäisch', 'kunstgeschicht', 'universität', 'untersuchung', 'aktuell', 'laufend', 'projekt', 'ästhetisch', 'setzung', 'kontext', 'forschungsfeld', 'herausgebilden', 'heidelberger', 'kunstgeschicht', 'keazor', 'international', 'führungsroll', 'einnehmen', 'thema', 'inzwischen', 'verstärkt', 'aufmerksamkeit', 'disziplin', 'film', 'musik', 'kunstgeschicht', 'erfahren', 'bibliografie', 'vertreterinn', 'disziplin', 'versammelnden', 'publikation', 'keazorwübbena', 'tatsache', 'musikvideo', 'kunsthistoriker', 'tag', 'eigen', 'sektion', 'widmen', 'fehlen', 'bearbeitung', 'themas', 'derzeit', 'adäqten', 'werkzeugen', 'analyse', 'präsentation', 'ergebnis', 'zahlreich', 'weisen', 'genuin', 'zweck', 'werbeträger', 'hinaus', 'ästhetisch', 'mehrwert', 'eingehender', 'betrachtung', 'heraus', 'fordern', 'aufzeigen', 'bereich', 'eigen', 'kunstform', 'entwickeln', 'künstlerisch', 'verknüpfung', 'text', 'bild', 'musik', 'vorhanden', 'eröffnen', 'szenarien', 'text', 'musik', 'kurz', 'schwall', 'heterogen', 'bildern', 'zusammenhalten', 'vielmehr', 'komplex', 'diskurs', 'eben', 'gestalten', 'musikvideo', 'visuell', 'produkt', 'referenzieren', 'dabei', 'immer', 'verwandte', 'medium', 'kino', 'fernsehfilm', 'werk', 'bildend', 'kunst', 'zeitpolitik', 'stellen', 'bisher', 'eng', 'verbindung', 'bild', 'text', 'musikaudio', 'eben', 'sehen', 'hierzu', 'keazorwübbena', 'vorgestellt', 'analysestruktur', 'musikvideo', 'hinblick', 'vislisierung', 'komplex', 'bezugsystem', 'problemfall', 'dar', 'heidelberger', 'institut', 'europäisch', 'kunstgeschicht', 'umfangreich', 'sammlung', 'digital', 'bereich', 'zurückgreifen', 'jedoch', 'fehlen', 'werkzeug', 'zept', 'vielgliedrigen', 'intermedial', 'bezug', 'erfassen', 'anschaulich', 'darstellen', 'erschließung', 'feld', 'unabding', 'bar', 'vorgeschlagen', 'beitrag', 'beispiel', 'titel', 'religion', 'amerikanisch', 'regisseur', 'tarsem', 'umsetzen', 'möglichkeit', 'video', 'annotation', 'frei', 'barer', 'quelloffen', 'plattform', 'kollaborativ', 'webbasiert', 'medienanalyse', 'basis', 'archiv', 'vorstellen', 'system', 'form', 'bereits', 'lang', 'global', 'context', 'universität', 'bewähren', 'rahmen', 'nutzen', 'aktiv', 'applikation', 'kurz', 'sagen', 'nutzern', 'gleichzeitig', 'erlauben', 'frei', 'gewählt', 'abschnitt', 'videos', 'art', 'annotation', 'spur', 'versehen', 'annotation', 'möglich', 'einzeln', 'sequenz', 'szene', 'thematik', 'direkt', 'referenzieren', 'spur', 'enthalten', 'annotation', 'bestimmt', 'text', 'bild', 'hinzugefügt', 'integriert', 'erlauben', 'system', 'film', 'bestimmt', 'nutzergruppen', 'zugänglich', 'jüngst', 'beispiel', 'gruppe', 'studierender', 'rahmen', 'geschichtssemi', 'applikation', 'verwenden', 'japanisch', 'propagandafilm', 'früh', 'analysieren', 'dabei', 'gezielt', 'wiederkehrend', 'thema', 'argumente', 'film', 'schlagworten', 'versehen', 'texttafel', 'transkribieren', 'übersetzen', 'querverweise', 'quellen', 'herstellen', 'hilfe', 'studierenden', 'film', 'verorten', 'integriert', 'timeline', 'sichtbar', 'daneben', 'ergeben', 'vergleich', 'spät', 'entstandenen', 'version', 'filmes', 'unterschied', 'narration', 'verwendet', 'breit', 'generisch', 'anlegen', 'still', 'beispielsweise', 'islamisch', 'predigen', 'videos', 'analysieren', 'erster', 'ergebnis', 'davon', 'deutsch', 'vorstellen', 'zeit', 'integration', 'arbeiten', 'womit', 'filmmetadaten', 'gemeinsam', 'ergebnis', 'projekt', 'einsehen', 'bildmetadan', 'ausgezeichnet', 'text', 'durchsuchbar', 'machen', 'ziel', 'integration', 'stark', 'betreiben', 'öffnen', 'grenze', 'hinaus', 'verankern', 'kommen', 'verschieden', 'schicht', 'audiovisuell', 'vislisierenden', 'erschließenden', 'struktur', 'verfolgen', 'heidelberger', 'lehrstuhl', 'neu', 'neu', 'kunstgeschicht', 'besonders', 'plattform', 'bieten', 'möglichkeit', 'gelegentlich', 'äußerst', 'dicht', 'musikvideo', 'artefakt', 'eingehen', 'erfassen', 'nachzeichnen', 'einspeisen', 'musikvideo', 'folge', 'konsultieren', 'analysieren', 'entsprechend', 'notat', 'beispielsweise', 'transkription', 'beschreibung', 'schlagwörter', 'medium', 'querverweisen', 'versehen', 'weg', 'medienbruch', 'vermeiden', 'bezugsyst', 'direkt', 'objekt', 'verdeutlichen', 'fallen', 'betrachten', 'clip', 'religion', 'referenz', 'werken', 'andrei', 'tarkowski', 'pierres', 'otto', 'lilienthal', 'option', 'information', 'quellen', 'referenzieren', 'erlauben', 'webbasiern', 'system', 'gemeinsam', 'zugriff', 'material', 'somit', 'ideal', 'basis', 'evolutionär', 'erarbeiten', 'ergebnis', 'forschergruppe', 'natürlich', 'studieren', 'bieten', 'rahmen', 'vorgeschlagen', 'beitrag', 'oben', 'genannt', 'musikvideo', 'möglichkeit', 'genutzt', 'abgrenzung', 'vergleichbar', 'system', 'vorstellen', 'funktion', 'frontend', 'kurz', 'technisch', 'anbindung', 'bestehend', 'datenaustausch', 'system', 'schnittstell', 'eingehen', 'stehen', 'insbesondere', 'integration', 'vordergrund', 'zeigen', 'kollaborativ', 'arbeitsumgebung', 'ressource', 'medium', 'annotation', 'versehen', 'perspektivisch', 'option', 'aufzeigen', 'dabei', 'frage', 'nachhaltigkeit', 'pflegen', 'daten', 'einbeziehen', 'beitrag', 'verdeutlichung', 'umstands', 'verzahnung', 'mehrwert', 'erreichen', 'zuvor', 'begrenzt', 'analog', 'möglichkeit', 'resp', 'weg', 'erzielen', 'geradezu', 'idealtypisch', 'modell', 'ausauf', 'gebiet', 'digital', 'publikation', 'thema', 'video', 'thrills', 'radio', 'geschichte', 'thema', 'analyse', 'autor', 'zusammen_keazor', 'auflage', 'rewind', 'fast', 'video', 'herausgeber', 'zusammen_keazor', 'imagebuilder', 'vergangenheit', 'gegenwart', 'zukunft', 'videoclip', 'autor', 'zusammen_keazor', 'herausgeber', 'ästhetisch', 'umsetzung', 'kontext', 'autor', 'herausgeber', 'zusammen', 'giessen', 'keazor', 'verfügbar', 'kapitel', 'video', 'sound', 'hrsg', 'thoben', 'zusammen_keazor', 'verfügbar', 'liying', 'tools', 'periodicals', 'tijdschrift', 'voor', 'november', 'berner', 'gietz', 'wenzlhuemer', 'geospatial', 'analysis', 'vislization', 'ieee', 'international', 'doiesciw', 'film', 'seiben', 'digital', 'video', 'filmportrait', 'global', 'politics', 'film', 'projektwebsit', 'kurzprofil', 'kunstgeschicht', 'sinologie', 'studieren', 'betreuen', 'visuell', 'ressource', 'betreuung', 'angeschlossen', 'gehören', 'konzeption', 'umsetzung', 'visuell', 'datenbanken', 'einsatz', 'forschung', 'lehren', 'groß', 'gehören', 'aktuell', 'arbeiten', 'konzeption', 'entwicklung', 'basierenden', 'bild', 'teil', 'decker', 'studieren', 'koordinator', 'tätigkeit', 'koordinator', 'betreuen', 'nutzer', 'bereits', 'seminar', 'musikethnologie', 'geschichte', 'betreuen', 'system', 'einsetzen', 'kunstgeschicht', 'geschichte', 'studieren', 'wiss', 'mitarbeiter', 'institut', 'universität', 'wiss', 'leitung', 'gemeinsam', 'projekt', 'sandrartnen', 'netasiern', 'kunst', 'jahrhundert', 'universität', 'april', 'wiss', 'mitarbeiter', 'projekt', 'ästhetisch', 'umsetzung', 'kontext', 'universität', 'saarland', 'universität', 'liegen', 'bereich', 'forschung', 'digital', 'kunstgeschicht'], ['bedeutung', 'wörterbüchern', 'einsprachig', 'zweisprache', 'mehrsprachig', 'wörterbücher', 'heutig', 'unterschätzen', 'geben', 'auskunft', 'wortbedeutung', 'dazugehörig', 'übersetzungen', 'bestandteil', 'kulturgüt', 'land', 'stellen', 'bedeutend', 'ressource', 'linked', 'data', 'technologie', 'dar', 'fast', 'land', 'wörterbücher', 'erstellen', 'traditionell', 'wörterbücher', 'gedruckt', 'form', 'ressource', 'digital', 'form', 'bestrebungen', 'kooperation', 'europäisch', 'ebene', 'eher', 'limitieren', 'führen', 'synergi', 'lexikographie', 'maschineller', 'optimal', 'nutzen', 'elexis', 'ändern', 'rahmen', 'elexis', 'projekt', 'infrastruktur', 'daten', 'entwickeln', 'eben', 'ansetzen', 'bereich', 'traditionell', 'lexikogrpahie', 'bereich', 'maschinell', 'verknüpfen', 'kooperation', 'austausch', 'verlagshäusern', 'fördern', 'gemeinsam', 'standard', 'arbeiten', 'austausch', 'daten', 'szenarien', 'fördern', 'infrastruktur', 'zugang', 'methode', 'tools', 'daten', 'ermöglichen', 'weit', 'verbreitet', 'gedanke', 'fördern', 'ziel', 'umsetzen', 'konsortium', 'partner', 'bilden', 'partner', 'befinden', 'institution', 'expertise', 'lexikographie', 'maschineller', 'technologie', 'digital', 'national', 'verlagshäuser', 'partner', 'expertise', 'bereich', 'normung', 'nachfolgend', 'liste', 'partner', 'bezeichnung', 'jeweilig', 'landessprache', 'angeben', 'institut', 'sefan', 'instituut', 'voor', 'lexicologie', 'università', 'studi', 'national', 'österreichisch', 'akademie', 'wissenschaft', 'institut', 'universidade', 'lisboa', 'nazional', 'ricerchen', 'italy', 'dänmark', 'kobenhavns', 'universitet', 'eesti', 'keel', 'instituut', 'real', 'elexis', 'infrastruktur', 'tools', 'erstellung', 'verarbeitung', 'daten', 'zugang', 'bereits', 'existierend', 'daten', 'anbieten', 'zukünftig', 'nutzer', 'potential', 'infrastruktur', 'vollends', 'ausnutzen', 'entwicklung', 'abhaltung', 'planen', 'weiter', 'programm', 'austausch', 'aktiv', 'fördern', 'zugang', 'daten', 'ermöglichen', 'gründen', 'verfügung', 'stellen', 'elexis', 'eng', 'bereits', 'existierend', 'clarin', 'dariah', 'bereits', 'vorhanden', 'infrastruktur', 'aufbauen', 'zugleich', 'infrastruktur', 'nah', 'zusammenbringen', 'poster', 'grundzüge', 'neu', 'europäisch', 'beschreiben', 'methode', 'maßnahme', 'oben', 'genannt', 'ziel', 'erreichen', 'präsentieren', 'weiter', 'speziell', 'nutzen', 'vorteil', 'elexis', 'infrastruktur', 'eingehen'], ['posterbeitrag', 'beschreiben', 'erstellung', 'thesaurus', 'österreichisch', 'strafrecht', 'jahrhundert', 'gehen', 'verbunden', 'themengebiet', 'quellen', 'quellen', 'dienen', 'kaum', 'erforschte', 'flugblätter', 'bekanntmachung', 'hinrichtung', 'jahrhundert', 'ammereradomeit', 'derzeit', 'modern', 'dokument', 'richtlini', 'annotieren', 'digital', 'verfügbarkeit', 'netz', 'vorbereiten', 'darstellung', 'sachverhalen', 'hinrichtung', 'führen', 'medial', 'überformen', 'peil', 'hart', 'beruhen', 'allerdings', 'entscheidung', 'damalig', 'stadtgericht', 'erschließung', 'berücksichtigen', 'laufen', 'jahrhundert', 'kraft', 'geben', 'land', 'einheitlich', 'streffen', 'jedoch', 'gelten', 'peinlich', 'gerichts', 'peinlich', 'kaiser', 'karls', 'daneben', 'etwa', 'land', 'gerichts', 'ordnung', 'oesterreich', 'ennß', 'erst', 'jahr', 'nennen', 'einheitlich', 'streffen', 'einführen', 'bereits', 'allgemein', 'gesetuch', 'verbrechen', 'bestrafungn', 'enannt', 'strafgesetuch', 'ablösen', 'gemein', 'tatbeständ', 'definieren', 'todesstrafe', 'belegen', 'laufen', 'zeit', 'teil', 'neu', 'tatbeständ', 'ergänzen', 'neu', 'definition', 'versehen', 'stattdessen', 'delikt', 'abschaffen', 'delikt', 'erschließenden', 'quellen', 'beschreiben', 'erwähnen', 'handeln', 'dabei', 'eigentlich', 'rechtstexte', 'flugblätter', 'öffentlich', 'hinrichtung', 'jahrhundert', 'berichten', 'quellen', 'todesurteil', 'bezeichnen', 'flugblätter', 'breit', 'publikum', 'wenden', 'delikt', 'beschreiben', 'kaum', 'verwendung', 'damals', 'delinquentinn', 'diebinnen', 'bezeichnen', 'eigentlich', 'tatestand', 'nennen', 'referenz', 'jeweilig', 'gesetzesstellen', 'fehlen', 'oft', 'gänzlich', 'gesamt', 'quellenmaterial', 'einzig', 'beleg', 'finden', 'direkt', 'gesetzestext', 'referenzieren', 'weit', 'herausforderung', 'erschließung', 'quellen', 'stellen', 'dar', 'etwa', 'diebstahl', 'diebstall', 'urfehde', 'urphed', 'gründen', 'toolgestützt', 'analyse', 'zuordnung', 'flugblätter', 'erschweren', 'ähnlich', 'gelagerten', 'projekt', 'zeitspanne', 'jahr', 'abdecken', 'delikt', 'erschließung', 'bewusst', 'gesetzlich', 'bestimmung', 'definieren', 'allgemein', 'definition', 'erarbeiten', 'vorliegend', 'projekt', 'quellennahe', 'definition', 'entscheiden', 'grund', 'thesaurus', 'essentiell', 'definition', 'bereitstellen', 'angabe', 'definition', 'stammen', 'erfassung', 'variant', 'framework', 'erstellung', 'möglich', 'darstellung', 'thesaurus', 'formal', 'sprache', 'sko', 'simple', 'organisation', 'system', 'erweiterung', 'sko', 'sko', 'simple', 'system', 'extension', 'label', 'zurückgegriffen', 'typologisierung', 'quellen', 'vorkommenden', 'delikt', 'vermeiden', 'quellennahe', 'differenziert', 'zuordnung', 'ermöglichen', 'erstellt', 'thesaurus', 'präsentieren', 'applikation', 'möglichkeit', 'darstellen', 'ergeben', 'biographisch', 'angabe', 'delinquentinn', 'alt', 'geschlecht', 'familienstand', 'herkunft', 'volltextsuch', 'text', 'erörtern', 'tatbeständ', 'rechtsnormen', 'miteinander', 'relation', 'setzen', 'weiter', 'verbindung', 'heutig', 'tatbeständen', 'herstellen', 'letztlich', 'mehrwert', 'zukünftig', 'userinn', 'bestehen', 'schließlich', 'möglich', 'thesaurus', 'thematisieren'], ['vortrag', 'beruhen', 'überlegung', 'theorie', 'praxis_erklärenden', 'annotation', 'literarischer', 'text', 'vordergrund', 'stehen', 'digital', 'aufbereitung', 'sinn', 'markup', 'anreicherung', 'text', 'annotation', 'teasys', 'explanatory', 'system', 'zirker', 'entwickeln', 'teasys', 'bieten', 'erklärend', 'annotation', 'verschieden', 'strukturieren', 'kategorie', 'darunter', 'sprachlich', 'erklärung', 'intertextlität', 'intratextuelle', 'verweisen', 'formal', 'aspekte', 'anmerkung', 'aufkommen', 'digital', 'annotation', 'eröffnen', 'neu', 'möglichkeit', 'gestaltung', 'erklärenden', 'annotation', 'text', 'entdecken', 'aufzubereiten', 'gelten', 'wesentlich', 'faktor', 'liegen', 'dabei', 'insbesondere', 'unterschied', 'annotation', 'gedruckt', 'buch', 'digital', 'medium', 'erlauben', 'schier', 'unbegrenzen', 'menge', 'information', 'dargeboten', 'inhalt', 'teasys', 'annotation', 'literarischer', 'text', 'entwickeln', 'langfristig', 'erläuterung', 'literarischer', 'text', 'disziplin', 'heranziehen', 'zirker', 'bereits', 'vorstellen', 'seither', 'teasys', 'technisch', 'annotation', 'speichern', 'nenlage', 'annotation', 'text', 'vorschlag', 'automatisieren', 'anbieten', 'vortrag', 'ergeben', 'technisch', 'projekt', 'theoretisch', 'problems', 'nämlich', 'frage', 'erklärenden', 'annotation', 'ambiguität', 'sprachlich', 'textuell', 'mehrdeutigkeit', 'umgehen', 'widmen', 'automatisierung', 'annotation', 'zusammenhang', 'ambiguität', 'ergeben', 'ambiguität', 'verstehen', 'doppel', 'mehrdeutigkeit', 'distinkt', 'bedeutung', 'sprachlich', 'einheit', 'praxis_erklärenden', 'annotation', 'alt', 'kulturtechnike', 'aufbereitung', 'literarisch', 'text', 'handeln', 'theoretisch', 'problem', 'erklärenden', 'annotation', 'bisher', 'systematisch', 'behandeln', 'assmann', 'eggeren', 'drucker', 'zirker', 'gehören', 'insbesondere', 'frage', 'verhältnis', 'textteile', 'textganz', 'text', 'kontext', 'erklärung', 'interpretation', 'ambiguität', 'aspekte', 'hoch', 'relevant', 'annotation', 'etwa', 'roman', 'beitragen', 'verbindung', 'lokal', 'global', 'textbedeutung', 'zeigen', 'fallbeispiel', 'dafür', 'etwa', 'taken', 'salt', 'erzählung', 'sammlung', 'doctor', 'prescriptions', 'einbetten', 'woraus', 'ambiguität', 'resultieren', 'wörtlich', 'metaphorisch', 'lesen', 'zirker', 'annotation', 'entsprechend', 'erläutern', 'beispielsweise', 'weit', 'kontexte', 'verwendung', 'spektrum', 'möglich', 'bedeutung', 'hinweisen', 'wiederum', 'text', 'zurückbezoge', 'ambiguität', 'mehrdeutigkeit', 'wörtern', 'ausdrücken', 'sätze', 'ganz', 'text', 'stellen', 'somit', 'herausforderung', 'digital', 'erläuternd', 'annotation', 'dar', 'annotation', 'automatisieren', 'jacke', 'negativbeispiel', 'automatisiert', 'annotation', 'literarischer', 'text', 'vortrag', 'vorstellen', 'finden', 'zirker', 'häufig', 'falsch', 'annotation', 'anbieten', 'weiterleitung', 'wissen', 'voraussetzen', 'textverstehe', 'bereits', 'zugrunde', 'liegen', 'teasys', 'treten', 'problem', 'hervor', 'anlage', 'neu', 'annotation', 'annotator', 'vorschlag', 'item', 'zugrunde', 'liegend', 'unterbreiten', 'fallen', 'ambiguität', 'treten', 'schwierigkeit', 'textverstehe', 'voraussetzen', 'richtig', 'annotation', 'jeweilig', 'kontext', 'wählen', 'nehmen', 'etwa', 'phrase', 'not', 'shakespeares', 'sonett', 'einleiten', 'sprecher', 'richten', 'analog', 'soliloquium', 'adressat', 'sinn', 'vorliegend', 'ambiguität', 'jedoch', 'automatisch', 'kontexte', 'übertragbar', 'not', 'soliloquium', 'verwenden', 'brutus', 'caesar', 'dialog', 'automatisierung', 'annotation', 'not', 'deshalb', 'schwierig', 'gerade', 'potentials', 'mehrdeutig', 'bedeuten', 'fall', 'eindeutigkeit', 'jeweilig', 'annotation', 'bedingung', 'disambiguierung', 'verweisen', 'hinweis', 'erstellen', 'weit', 'annotation', 'erhältlich', 'nützlich', 'bleiben', 'passieren', 'annotation', 'ambiguität', 'berücksichtigen', 'hierzu', 'geben', 'szenarien', 'erklärend', 'annotation', 'disambiguieren', 'textstelle', 'text', 'erklärend', 'annotation', 'weisen', 'nutzer', 'ambiguität', 'insbesondere', 'literarisch', 'text', 'bieten', 'distinkt', 'denotatione', 'erklärend', 'annotation', 'führen', 'strategisch', 'weise', 'zirker', 'vorb', 'wahrnehmung', 'ambiguität', 'tatsächlich', 'vorliegen', 'eben', 'fall', 'vereindeutigung', 'textes', 'resultieren', 'qlitäten', 'literarischer', 'werk', 'lässen', 'möglicherweise', 'ermöglichen', 'klar', 'interpretation', 'disambiguierung', 'erforderlich', 'etwa', 'zug', 'sprachwandel', 'englisch', 'denken', 'heute', 'geläufig', 'bedeutung', 'nice', 'jahrhundert', 'völlig', 'denotatione', 'besaßen', 'fall', 'annotation', 'ambiguität', 'ästhetisch', 'merkmal', 'textes', 'besonderer', 'weise', 'hervortret', 'lassen', 'hintergrund', 'rücken', 'ambiguität', 'intern', 'extern', 'denken', 'dramatisch', 'ironie', 'fall', 'annotator', 'erklärung', 'potentiell', 'ambig', 'anbieten', 'global', 'textverstehe', 'beeinflussen', 'treffen', 'etwa', 'biographisch', 'lesarten', 'sonett', 'shakespeares', 'lokal', 'ambiguitäten', 'strategisch', 'text', 'hineingelesen', 'sonett', 'reden', 'annotation', 'verweis', 'shakespeares', 'frau', 'interpretieren', 'theoretisch', 'problem', 'überlegung', 'kurz', 'fallbeispiel', 'anknüpfen', 'bisher', 'systematisch', 'reflektieren', 'gelten', 'frage', 'inwieweit', 'erklärend', 'annotation', 'komplexität', 'ambiguität', 'literarischer', 'text', 'gerecht', 'digital', 'medium', 'scheinbar', 'unbegrenzen', 'raum', 'annotation', 'neu', 'möglichkeit', 'lösung', 'frage', 'problem', 'bieten', 'resultieren', 'daraus', 'wiederum', 'neu', 'nämlich', 'reflexion', 'mehrwert', 'verlust', 'geschilderten', 'hermeneutisch', 'schwierigkeit', 'ergeben', 'jacke', 'wenden', 'digital', 'erklärenden', 'annotation', 'verhältnis', 'ambiguität', 'resultieren', 'daraus', 'fällen', 'darlegen', 'klärung', 'verdunkelung', 'notwendigkeit', 'überforderung', 'überfrachtung', 'nutzer', 'gefahr', 'information', 'anbieten', 'vortrag', 'widmen', 'frage', 'ausgewählt', 'beispiel', 'versuchen', 'folgend', 'aspekte', 'präsentieren', 'anzureißen', 'theoretisch', 'grundlag', 'erklärenden', 'annotation', 'hermeneutisch', 'grundlag', 'hinblick', 'ambiguität', 'nah', 'beleuchten', 'verhältnis', 'digital', 'medium', 'literarischer', 'annotation', 'konzeptlisieren', 'hintergrund', 'erschweren', 'bedingung', 'ambiguität', 'automatisierung', 'annotation', 'ambiger', 'digital', 'medium', 'theoretisch', 'hinsicht', 'vorantreiben'], ['poster', 'präsentieren', 'teasys', 'explanatory', 'system', 'bauerzirker', 'möglichkeit', 'heuristisch', 'tool', 'lehr', 'lernprozessen', 'bieten', 'projekt', 'annotier', 'studierender', 'kollaborativ', 'text', 'literatur', 'teasys', 'struktur', 'funktion', 'bereits', 'vorstellen', 'liegen', 'schwerpunkt', 'prozess', 'kollaborativ', 'annotation', 'digital', 'medium', 'praxis_erklärenden', 'anreicherung', 'textes', 'verständlich', 'digitalisierung', 'grundlegend', 'beeinflussen', 'erstellung', 'annotieren', 'buch', 'editioner', 'einzelforschern', 'vorbehalen', 'eröffnen', 'digitalität', 'neu', 'möglichkeit', 'generierung', 'social', 'digital', 'editioner', 'plattform', 'thoreau', 'infinit', 'ulysses', 'pyncheonwiki', 'tools', 'annotation', 'studio', 'annotat', 'hypothesis', 'ermöglichen', 'lesern', 'erläuterung', 'wörtern', 'passagen', 'beitragen', 'dadurch', 'lösen', 'grenze', 'leser', 'sahlen', 'gleichzeitig', 'geben', 'digital', 'edition', 'zeitlich', 'räumlich', 'einschränkung', 'annotatoren', 'kontinuierlich', 'neu', 'information', 'annotation', 'hinzufügen', 'digitalität', 'sinn', 'kritik', 'unterziehen', 'führen', 'endlos', 'abhandlung', 'wort', 'textes', 'entstehen', 'irrelevant', 'information', 'infolgedessen', 'digital', 'annotation', 'führen', 'laufen', 'digital', 'erklärend', 'annotation', 'gefahr', 'nutzer', 'anliegen', 'text', 'verstehen', 'verwirren', 'irre', 'führen', 'bauerzirker', 'teasys', 'steuern', 'prozess', 'nutzen', 'entstandenen', 'annotation', 'kritisch', 'reflektieren', 'geschehen', 'studentisch', 'gruppe', 'häufig', 'anstoß', 'selbständig', 'weiterarbeit', 'gruppe', 'geben', 'dienen', 'annotier', 'methode', 'erarbeitung', 'historisch', 'kulturell', 'distanter', 'text', 'ebenso', 'erwerb', 'fähigkeit', 'dabei', 'lernen', 'studierender', 'eigen', 'vorgehensweise', 'reflektieren', 'überprüfbar', 'teasys', 'lehrmethode', 'einsetzen', 'studierender', 'anregen', 'eigen', 'unverständnis', 'textes', 'reflektieren', 'elemente', 'textes', 'tragen', 'schwierig', 'empfinden', 'information', 'benötigen', 'schwierigkeit', 'überwinden', 'kommen', 'heuristik', 'teasys', 'spiel', 'annotation', 'strukturieren', 'kategorie', 'information', 'sprache', 'form', 'intertextlität', 'bauerzirker', 'eben', 'komplexität', 'insgesamt', 'zielen', 'konkret', 'bauerzirker', 'strukturierung', 'annotation', 'helfen', 'studierenden', 'somit', 'frage', 'formulieren', 'andernfalls', 'vielleicht', 'stoßen', 'wort', 'wort', 'jahrhundert', 'bedeuten', 'häufig', 'dabei', 'deutlich', 'textes', 'textteile', 'oft', 'gewiß', 'expertenwissen', 'erkennen', 'oftmals', 'lehrend', 'beigesteuern', 'strukturierung', 'studierender', 'leicht', 'experte', 'kombination', 'expertise', 'kritik', 'führen', 'generierung', 'social', 'austausch', 'gruppe', 'effizient', 'weise', 'qlitativ', 'verifizieren', 'erzeugen', 'jannidis', 'kohle', 'rehbein', 'publikation', 'annotation', 'stellen', 'zusätzlich', 'motivation', 'student', 'dar', 'hoch', 'fachlich', 'niveau', 'produzieren', 'stroud', 'annotation', 'verbessern', 'kontinuierlich', 'weiterarbeit', 'rallen', 'bergen', 'risiko', 'hinsicht', 'verwend', 'zitierbarkeit', 'kollaborativ', 'entstandenen', 'wissens', 'poster', 'stellen', 'lehr', 'lernprozesse', 'kollaborativ', 'dar', 'nachhaltigkeit', 'projekt', 'mehrwert', 'heuristik', 'teasys', 'hinblick', 'digital', 'methode']]\n"
     ]
    }
   ],
   "source": [
    "# creating bigrams and trigrams from lemmatized words\n",
    "data_bigrams_trigrams = create_bigrams_trigrams(list_all_texts)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating id2word and bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 2), (3, 1), (4, 6), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (17, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 2), (34, 3), (35, 2), (36, 4), (37, 6), (38, 1), (40, 1), (41, 1), (43, 1), (46, 1), (47, 1), (48, 1), (50, 1), (51, 1), (52, 2), (53, 2), (54, 1), (56, 4), (57, 1), (58, 1), (59, 1), (60, 1), (61, 3), (62, 1), (63, 3), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 4), (71, 1), (73, 3), (74, 1), (75, 2), (76, 1), (77, 1), (78, 3), (79, 1), (80, 1), (81, 1), (82, 2), (83, 1), (84, 3), (85, 1), (86, 1), (87, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 2), (101, 1), (102, 1), (103, 1), (105, 1), (106, 1), (108, 1), (109, 3), (110, 3), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 7), (118, 1), (119, 1), (120, 1), (122, 4), (124, 1), (125, 1), (127, 1), (128, 2), (129, 2), (130, 6), (131, 1), (132, 2), (133, 1), (134, 1), (137, 1), (139, 1), (140, 1), (141, 2), (142, 1), (143, 2), (144, 1), (145, 1), (146, 4), (147, 3), (149, 2), (150, 1), (151, 1), (153, 1), (154, 1), (156, 1), (157, 1), (158, 1), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (166, 1), (167, 1), (169, 1), (170, 1), (172, 1), (173, 1), (174, 5), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 1), (182, 1), (184, 1), (186, 2), (187, 1), (188, 4), (190, 1), (191, 1), (192, 1), (193, 1), (194, 1), (195, 1), (197, 1), (198, 2), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 2), (205, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 1), (211, 2), (212, 1), (213, 1), (215, 1), (216, 2), (218, 1), (219, 1), (220, 1), (221, 7), (223, 1), (224, 1), (225, 1), (226, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (234, 1), (235, 1), (236, 1), (238, 1), (239, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 1), (249, 1), (251, 1), (252, 1), (253, 1), (255, 2), (256, 1), (257, 1), (258, 1), (260, 1), (261, 1), (262, 1), (263, 1), (264, 1), (265, 1), (266, 1), (267, 2), (268, 1), (270, 2), (272, 1), (273, 1), (274, 1), (275, 2), (276, 1), (277, 1), (278, 2), (279, 2), (281, 2), (282, 1), (283, 1), (284, 1), (285, 1), (287, 6), (288, 4), (290, 1), (291, 4), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (297, 1), (298, 1), (299, 1), (300, 1), (302, 1), (303, 1), (304, 1), (305, 2), (306, 1), (307, 1), (308, 3), (309, 1), (310, 1), (312, 1), (315, 1), (316, 1), (317, 1), (318, 1), (319, 1), (320, 1), (321, 1), (322, 1), (323, 3), (324, 1), (325, 1), (326, 1), (327, 1), (328, 1), (330, 2), (331, 2), (332, 1), (333, 1), (335, 1), (336, 1), (337, 1), (338, 1), (339, 1), (340, 10), (341, 1), (342, 2), (343, 1), (345, 2), (347, 1), (348, 7), (349, 2), (351, 1), (352, 1), (353, 1), (354, 2), (355, 1), (356, 1), (357, 1), (358, 1), (359, 1), (360, 1), (361, 1), (362, 1), (363, 1), (364, 3), (366, 1), (367, 1), (368, 1), (369, 1), (370, 1), (371, 1), (372, 1), (373, 4), (374, 1), (376, 7), (377, 1), (378, 1), (380, 1), (383, 1), (384, 1), (385, 1), (386, 1), (387, 1), (388, 4), (389, 1), (390, 1), (391, 3), (392, 1), (393, 1), (395, 2), (396, 1), (397, 3), (398, 1), (400, 1), (402, 1), (403, 4), (404, 1), (405, 1), (406, 1), (408, 1), (409, 1), (410, 3), (412, 1), (413, 1), (414, 1), (415, 1), (417, 1), (418, 1), (419, 1), (420, 2), (421, 1), (423, 1), (424, 1), (426, 1)], [(4, 3), (34, 3), (36, 3), (49, 2), (100, 4), (135, 2), (155, 3), (171, 2), (186, 3), (188, 2), (280, 3), (345, 4), (365, 3), (427, 1), (428, 1), (429, 1), (431, 2), (432, 1), (434, 1), (435, 3), (436, 1), (437, 1), (438, 1), (439, 1), (440, 1), (441, 5), (442, 1), (443, 2), (444, 1), (445, 2), (446, 1), (447, 1), (448, 1), (449, 1), (450, 1), (451, 1), (452, 2), (453, 1), (454, 1), (455, 3), (456, 1), (457, 1), (458, 2), (459, 1), (460, 1), (461, 2), (463, 1), (464, 1), (465, 1), (466, 1), (467, 1), (468, 1), (469, 3), (470, 1), (471, 1), (472, 1), (473, 1), (474, 1), (476, 4), (477, 1), (478, 1), (479, 1), (481, 1), (482, 1), (488, 1), (489, 1), (490, 1), (491, 1), (493, 1), (494, 2), (495, 2), (496, 1), (497, 1), (499, 1), (500, 2), (501, 1), (502, 1), (503, 2), (504, 1), (506, 1), (508, 1), (514, 2), (516, 3), (519, 1), (521, 2), (522, 1), (525, 2), (526, 1), (527, 1), (528, 6), (529, 1), (530, 1), (531, 1), (532, 1), (533, 1), (534, 1), (535, 2), (536, 1), (537, 1), (538, 1), (539, 1), (540, 1), (541, 1), (542, 1), (543, 3), (545, 1), (546, 1), (547, 1), (548, 1), (549, 1), (550, 1), (551, 1), (552, 1), (553, 1), (554, 1), (555, 1), (556, 2), (558, 1), (560, 3), (561, 1), (562, 3), (563, 1), (565, 1), (567, 1), (569, 1), (570, 1), (571, 1), (572, 1), (573, 1), (574, 1), (575, 1), (577, 3), (578, 1), (579, 2), (580, 1), (581, 1), (583, 1), (584, 1), (585, 2), (586, 2), (587, 1), (588, 2), (590, 2), (591, 1), (592, 3), (593, 2), (594, 2), (595, 2), (596, 1), (597, 8), (598, 1), (599, 3), (600, 1), (601, 1), (602, 1), (603, 1), (604, 1), (605, 1), (606, 1), (607, 1), (608, 1), (609, 1), (610, 1), (611, 1), (612, 1), (613, 3), (615, 2), (616, 1), (617, 3), (618, 1), (619, 1), (620, 6), (622, 4), (624, 1), (625, 1), (626, 1), (627, 1), (629, 1), (630, 1), (632, 1), (633, 1), (635, 1), (636, 2), (637, 1), (638, 1), (639, 1), (640, 1), (641, 1), (642, 2), (643, 1), (644, 1), (645, 1), (646, 1), (647, 1), (648, 1), (649, 2), (650, 2), (651, 1), (652, 1), (653, 1), (654, 1), (656, 3), (657, 1), (658, 3), (659, 1), (660, 1), (661, 1), (662, 1), (664, 1), (665, 1), (666, 1), (667, 1), (668, 1), (669, 1), (670, 1), (671, 1), (672, 1), (673, 1), (674, 1), (675, 1), (676, 1), (678, 1), (679, 2), (680, 1), (681, 1), (682, 1), (683, 4), (687, 1), (688, 1), (689, 1), (690, 1), (691, 1), (693, 1), (694, 1), (695, 1), (696, 1), (697, 1), (698, 1), (699, 1), (701, 1), (702, 1), (703, 1), (704, 1), (706, 1), (707, 1), (708, 6), (710, 1), (712, 1), (713, 1), (714, 1), (715, 2), (716, 1), (717, 1), (718, 1), (719, 1), (721, 1), (723, 4), (724, 1), (725, 1), (726, 1), (728, 1), (729, 1), (730, 5), (731, 1), (732, 2), (733, 1), (734, 1), (735, 1), (736, 1), (737, 1), (738, 3), (741, 2), (742, 1), (744, 3), (745, 1), (746, 1), (747, 2), (748, 1), (749, 1), (751, 1), (752, 1), (754, 1), (755, 3), (756, 1), (757, 1), (759, 1), (760, 1), (762, 1), (763, 1), (764, 1), (765, 1), (766, 1), (767, 4), (768, 1), (769, 1), (770, 4), (771, 1), (772, 1), (773, 1)], [(2, 1), (36, 3), (61, 1), (168, 1), (183, 7), (214, 2), (222, 2), (240, 2), (287, 2), (399, 1), (430, 1), (445, 1), (487, 6), (500, 1), (507, 1), (512, 1), (517, 1), (521, 2), (524, 1), (543, 1), (544, 1), (577, 2), (634, 1), (700, 2), (705, 1), (739, 1), (743, 1), (761, 2), (774, 1), (775, 1), (776, 1), (777, 1), (778, 1), (779, 1), (780, 1), (781, 3), (782, 1), (783, 1), (784, 1), (785, 1), (786, 1), (787, 1), (788, 1), (789, 1), (790, 1), (791, 1), (792, 1), (793, 1), (794, 1), (795, 1), (796, 1), (797, 5), (798, 1), (800, 2), (801, 2), (802, 4), (804, 1), (805, 1), (806, 1), (807, 1), (808, 1), (809, 2), (810, 1), (812, 1), (813, 1), (814, 1), (815, 2), (816, 1), (817, 1), (818, 1), (819, 1), (820, 1), (821, 1), (822, 1), (823, 1), (824, 1), (825, 2), (826, 1), (827, 1), (828, 1), (829, 1), (830, 2), (831, 1), (832, 1), (833, 1), (834, 4), (835, 1), (836, 1), (837, 1), (838, 1), (840, 1), (841, 1), (842, 1), (843, 1), (844, 1), (845, 1), (846, 1), (847, 2), (848, 2), (849, 1), (850, 1), (851, 1), (852, 1), (853, 1), (854, 1), (855, 1), (856, 1), (857, 1), (858, 1), (859, 1), (860, 1), (862, 2), (863, 1), (864, 3), (865, 1), (866, 3), (867, 1), (868, 1), (869, 1), (870, 1), (871, 1), (872, 1), (873, 1)], [(39, 1), (44, 3), (63, 2), (107, 3), (214, 2), (217, 2), (248, 1), (259, 1), (289, 1), (350, 1), (416, 2), (422, 1), (443, 1), (480, 1), (484, 1), (486, 1), (492, 1), (494, 1), (513, 1), (518, 1), (525, 1), (564, 1), (621, 2), (650, 6), (655, 1), (656, 1), (720, 1), (723, 1), (758, 1), (799, 2), (806, 1), (807, 1), (862, 1), (868, 1), (872, 1), (874, 1), (875, 1), (876, 1), (877, 1), (878, 2), (879, 1), (880, 1), (881, 2), (882, 1), (883, 1), (884, 1), (885, 1), (886, 1), (887, 1), (888, 1), (889, 1), (890, 1), (891, 1), (892, 2), (893, 1), (894, 1), (895, 1), (896, 2), (897, 5), (898, 5), (899, 2), (900, 1), (901, 1), (902, 1), (903, 1), (904, 1), (905, 1), (906, 2), (907, 1), (908, 2), (909, 1), (910, 1), (911, 1), (912, 1), (913, 1), (914, 1), (915, 1), (916, 1), (917, 1), (918, 1), (919, 1), (920, 1), (921, 1), (922, 1), (923, 1), (924, 2), (925, 1), (926, 1), (927, 1), (928, 4), (929, 1), (930, 1), (931, 1), (932, 1), (933, 1), (934, 2), (935, 1), (936, 1), (937, 1), (938, 1), (939, 1), (940, 1), (941, 1), (942, 1), (943, 1), (944, 1), (945, 1), (946, 1), (947, 3), (948, 2), (949, 1), (950, 1), (951, 2), (952, 1), (953, 1), (954, 1), (955, 1), (956, 1), (957, 1), (958, 2), (959, 1), (960, 1), (961, 1), (962, 1), (963, 2), (964, 1), (965, 1), (966, 1), (967, 2), (968, 1), (969, 1), (970, 1), (971, 1), (972, 1), (973, 1), (974, 2), (975, 3), (976, 1), (977, 1), (978, 1), (979, 1), (980, 1), (981, 1), (982, 2), (983, 3), (984, 1), (985, 1), (986, 1), (987, 5), (988, 1), (989, 1), (990, 1), (991, 1), (992, 1), (993, 1), (994, 1), (995, 1), (996, 1), (997, 1), (998, 1), (999, 1), (1000, 1), (1001, 1), (1002, 1), (1003, 1), (1004, 1), (1005, 1), (1006, 1), (1007, 1), (1008, 1)], [(18, 3), (117, 4), (126, 5), (185, 3), (269, 4), (311, 3), (330, 2), (340, 15), (391, 4), (425, 2), (441, 36), (475, 3), (515, 3), (556, 2), (592, 2), (613, 4), (692, 2), (753, 2), (775, 4), (783, 3), (924, 5), (1009, 1), (1010, 1), (1011, 1), (1012, 17), (1013, 1), (1014, 1), (1015, 1), (1016, 1), (1017, 2), (1019, 1), (1020, 1), (1021, 2), (1022, 1), (1023, 1), (1024, 1), (1025, 1), (1026, 1), (1027, 2), (1028, 1), (1029, 3), (1031, 2), (1033, 1), (1035, 1), (1036, 1), (1037, 1), (1038, 1), (1039, 1), (1041, 1), (1042, 1), (1043, 2), (1044, 1), (1045, 1), (1046, 1), (1047, 2), (1048, 2), (1049, 1), (1050, 1), (1051, 1), (1052, 2), (1053, 2), (1054, 1), (1055, 1), (1056, 1), (1057, 1), (1058, 1), (1059, 1), (1060, 1), (1061, 1), (1062, 1), (1063, 1), (1064, 1), (1065, 1), (1066, 1), (1067, 5), (1068, 5), (1069, 3), (1070, 1), (1071, 1), (1073, 1), (1075, 1), (1076, 1), (1077, 2), (1078, 1), (1079, 1), (1081, 1), (1082, 1), (1083, 1), (1084, 1), (1085, 2), (1086, 1), (1087, 2), (1088, 1), (1089, 1), (1090, 1), (1091, 1), (1093, 2), (1094, 1), (1095, 1), (1097, 1), (1098, 1), (1099, 2), (1100, 1), (1102, 1), (1103, 1), (1104, 1), (1105, 1), (1106, 2), (1108, 1), (1109, 1), (1111, 2), (1112, 1), (1113, 1), (1114, 1), (1115, 1), (1116, 1), (1117, 1), (1118, 2), (1119, 7), (1120, 2), (1121, 1), (1122, 1), (1123, 3), (1124, 1), (1125, 1), (1126, 1), (1127, 1), (1128, 1), (1129, 1), (1130, 1), (1131, 1), (1132, 3), (1133, 2), (1134, 1), (1135, 1), (1136, 1), (1137, 1), (1138, 1), (1139, 2), (1140, 1), (1141, 1), (1142, 1), (1143, 1), (1145, 1), (1146, 4), (1147, 1), (1148, 1), (1149, 1), (1150, 1), (1151, 1), (1152, 1), (1153, 1), (1155, 2), (1156, 1), (1157, 3), (1158, 2), (1159, 2), (1160, 3), (1161, 1), (1162, 1), (1163, 1), (1164, 1), (1165, 2), (1167, 1), (1168, 1), (1169, 1), (1170, 5), (1171, 1), (1172, 2), (1173, 1), (1174, 1), (1176, 3), (1177, 5), (1178, 1), (1179, 1), (1180, 2), (1181, 1), (1182, 2), (1183, 1), (1184, 1), (1185, 1), (1186, 3), (1187, 1), (1189, 1), (1190, 2), (1191, 1), (1192, 2), (1193, 1), (1194, 1), (1195, 2), (1196, 1), (1197, 1), (1198, 2), (1199, 1), (1200, 2), (1201, 1), (1202, 1), (1203, 1), (1205, 1), (1206, 6), (1207, 1), (1208, 2), (1209, 1), (1210, 1), (1211, 1), (1212, 1), (1213, 1)], [(84, 2), (116, 1), (174, 1), (240, 2), (375, 1), (401, 3), (411, 1), (441, 10), (505, 1), (510, 2), (557, 1), (559, 3), (576, 4), (588, 4), (589, 1), (623, 1), (642, 1), (649, 1), (684, 1), (685, 4), (781, 1), (801, 1), (836, 2), (882, 1), (903, 1), (960, 1), (976, 1), (1018, 1), (1030, 1), (1032, 1), (1034, 1), (1040, 1), (1067, 1), (1072, 1), (1074, 1), (1080, 1), (1092, 1), (1096, 2), (1101, 1), (1107, 1), (1110, 1), (1139, 1), (1144, 3), (1154, 1), (1155, 1), (1158, 1), (1166, 1), (1170, 6), (1172, 5), (1175, 1), (1188, 1), (1198, 1), (1204, 1), (1214, 1), (1215, 1), (1216, 1), (1217, 1), (1218, 1), (1219, 2), (1220, 1), (1221, 1), (1222, 4), (1223, 1), (1224, 1), (1225, 1), (1226, 1), (1227, 1), (1228, 1), (1229, 2), (1230, 1), (1231, 1), (1232, 1), (1233, 2), (1234, 1), (1235, 1), (1236, 1), (1237, 1), (1238, 1), (1239, 1), (1240, 1), (1241, 1), (1242, 1), (1243, 1), (1244, 1), (1245, 1), (1246, 1), (1247, 1), (1248, 1), (1249, 2), (1250, 1), (1251, 1), (1252, 1), (1253, 1), (1254, 2), (1255, 1), (1256, 1), (1257, 1), (1258, 1), (1259, 1), (1260, 1), (1261, 1), (1262, 1), (1263, 1), (1264, 1), (1265, 1), (1266, 1), (1267, 2), (1268, 2), (1269, 1), (1270, 1), (1271, 2), (1272, 1), (1273, 1), (1274, 1), (1275, 1), (1276, 1), (1277, 1), (1278, 1), (1279, 1), (1280, 1), (1281, 1), (1282, 1), (1283, 1), (1284, 1), (1285, 1), (1286, 1), (1287, 2), (1288, 1), (1289, 1), (1290, 1), (1291, 1), (1292, 1), (1293, 1), (1294, 1), (1295, 1), (1296, 1), (1297, 2), (1298, 1), (1299, 1), (1300, 1), (1301, 1), (1302, 2), (1303, 1), (1304, 1), (1305, 1), (1306, 1), (1307, 1), (1308, 1), (1309, 1), (1310, 1), (1311, 1), (1312, 1), (1313, 1), (1314, 1), (1315, 1), (1316, 1), (1317, 1), (1318, 1), (1319, 2), (1320, 1), (1321, 1), (1322, 1), (1323, 1), (1324, 1), (1325, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# id2word as dictionary where every word is referenced with id\n",
    "id2word = corpora.Dictionary(data_bigrams_trigrams)\n",
    "# rename variable\n",
    "texts = data_bigrams_trigrams\n",
    "\n",
    "# corpus as dictionary that contains a list of tuples for each document, tuples contain (id, no. of appearances of the word\n",
    "# some index numbers are missing due to the tf-idf weighting \n",
    "corpus = tf_idf(id2word, texts)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' FIND THE PERFECT PARAMETERS\n",
    "random state:\n",
    "update_every\n",
    "chunksize: how many documents are processed at once? Higher: speed up process\n",
    "passes: iterations\n",
    "'''\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=bow,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=7,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation baseline: Topic coherence to evaluate the model's quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score:  0.3721166451208203\n"
     ]
    }
   ],
   "source": [
    "# Compute baseline coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=list_all_texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning (hyper-)parameters: Find optimal settings for topic number, alpha and beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' FILL IN '''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of final topic modeling with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.008*\"kunstgeschicht\" + 0.008*\"quellen\" + 0.007*\"system\" + 0.006*\"text\" + 0.006*\"keazor\" + 0.006*\"film\" + 0.005*\"annotation\" + 0.005*\"digital\" + 0.005*\"musikvideo\" + 0.005*\"möglichkeit\"'), (1, '0.001*\"digital\" + 0.001*\"text\" + 0.001*\"annotation\" + 0.001*\"analyse\" + 0.001*\"lexikalisch\" + 0.001*\"historisch\" + 0.001*\"system\" + 0.001*\"social\" + 0.001*\"ressource\" + 0.001*\"erster\"'), (2, '0.046*\"annotation\" + 0.018*\"text\" + 0.017*\"ambiguität\" + 0.014*\"digital\" + 0.011*\"teasys\" + 0.008*\"erklärenden\" + 0.007*\"literarischer\" + 0.007*\"textes\" + 0.006*\"vgl\" + 0.006*\"information\"'), (3, '0.001*\"annotation\" + 0.001*\"digital\" + 0.001*\"text\" + 0.001*\"ambiguität\" + 0.001*\"teasys\" + 0.001*\"social\" + 0.001*\"erklärenden\" + 0.001*\"etwa\" + 0.001*\"vgl\" + 0.001*\"neu\"'), (4, '0.018*\"infrastruktur\" + 0.015*\"daten\" + 0.013*\"elexis\" + 0.010*\"fördern\" + 0.010*\"partner\" + 0.008*\"bereits\" + 0.008*\"bereich\" + 0.008*\"austausch\" + 0.008*\"wörterbücher\" + 0.008*\"zugang\"'), (5, '0.029*\"digital\" + 0.013*\"text\" + 0.010*\"lexikalisch\" + 0.009*\"fachlich\" + 0.009*\"ressource\" + 0.009*\"erster\" + 0.008*\"thematisch\" + 0.008*\"verfahren\" + 0.008*\"frauenbewegung\" + 0.008*\"bereichen\"'), (6, '0.019*\"social\" + 0.017*\"graph\" + 0.014*\"data\" + 0.014*\"human\" + 0.014*\"application\" + 0.014*\"image\" + 0.012*\"computer\" + 0.012*\"users\" + 0.012*\"visualization\" + 0.010*\"digital\"')]\n"
     ]
    }
   ],
   "source": [
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.gensim_models.prepare(lda_model, bag_of_words_corpus, id2word, mds=\"mmds\", R=30)\n",
    "# vis\n",
    "\n",
    "print(lda_model.print_topics())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "265bbd40db63aa34df1bd83f77ecf498882faae903508c6e893ae6addaebaa43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
