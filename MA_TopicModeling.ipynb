{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Code for Master's Thesis: Topic Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Questions\n",
    "\n",
    "1. Which topics can be found in the abstracts from DHd conferences between 2014 and 2023 with Topic Modeling?\n",
    "\n",
    "2. How have the topics been changing throughout the years - which trends are perceptible?\n",
    "\n",
    "3. Which topics appear in the same abstracts frequently and therefore have a high topic similarity?\n",
    "\n",
    "4. With regard to the use of different scientific methods, which developments are perceptible?\n",
    "\n",
    "5. Which researchers contribute to the conference particularly frequently with abstracts, in which teams do they contribute and how have the teams been changing?\n",
    "\n",
    "6. Which clusters of researchers can be found with regard to topics and how have the clusters been changing?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 1</span></font> Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "cell #1"
    ]
   },
   "outputs": [],
   "source": [
    "#general imports\n",
    "import re\n",
    "import numpy as np\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "#Visualisations\n",
    "import pygal \n",
    "from pygal.style import Style\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#importing functions from MA_Preprocessing (Both imports necessary!)\n",
    "import import_ipynb\n",
    "from MA_Preprocessing import open_list, save_object, open_variable, check_directory\n",
    "\n",
    "#LDA\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "#RQ2: Mann-Kendall Test\n",
    "import pymannkendall as mk\n",
    "\n",
    "#RQ3: Topic Similarity\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, set_link_color_palette\n",
    "\n",
    "#RQ5: Network Analysis\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "\n",
    "#RQ6: Authors-Topic-Analysis\n",
    "import itertools\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 2</span></font> Importing all variables needed from the preprocessing notebook to this one and importing the saved variables from the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "cell #2"
    ]
   },
   "outputs": [],
   "source": [
    "%store -r number_pdf_docs\n",
    "%store -r number_xml_docs\n",
    "%store -r number_docs\n",
    "%store -r docnames\n",
    "%store -r filenames\n",
    "%store -r filenames_xml\n",
    "%store -r filenames_pdf\n",
    "%store -r all_freely_selectable_keywords\n",
    "%store -r used_keywords_freely_selectable\n",
    "%store -r used_keywords_predetermined\n",
    "%store -r authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 3</span></font> Opening stored variables and checking if the necessary folders for variables, models and figures exist (necessary if the preprocessing notebook was not executed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "cell #3"
    ]
   },
   "outputs": [],
   "source": [
    "#Variables that are stored in the Thesis folders\n",
    "corpus = open_variable('Variables/', 'corpus.pckl')\n",
    "id2word = open_variable('Variables/', 'id2word.pckl')\n",
    "corrected_list_of_texts = open_variable('Variables/', 'corrected_list_of_texts.pckl')\n",
    "data_bigrams_trigrams = open_variable('Variables/', 'data_bigrams_trigrams.pckl')\n",
    "\n",
    "check_directory('Models/')\n",
    "\n",
    "rqs = ['RQ1', 'RQ2', 'RQ3', 'RQ4', 'RQ5', 'RQ6', ]    \n",
    "for section in rqs:\n",
    "    check_directory('Figures/' + section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 4</span></font> Implemeting a list of indexes as well as a list containing all document names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "cell #4"
    ]
   },
   "outputs": [],
   "source": [
    "indexes = [0]\n",
    "textnames = []\n",
    "for sublist in docnames:\n",
    "    indexes.append(len(sublist) + indexes[-1])\n",
    "    textnames = textnames + sublist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 5</span></font> Implementing several lists for authors and author teams which are needed for later tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "cell #5"
    ]
   },
   "outputs": [],
   "source": [
    "# contains all authors' names, with duplicates if author contributed several times\n",
    "all_authors = []\n",
    "# contains all teams that contributed to the conference, not splitted by years\n",
    "all_author_teams = []\n",
    "\n",
    "# authors contains all teams that contributed to the conference, splitted  by years\n",
    "for year in authors:\n",
    "    all_author_teams = all_author_teams + year\n",
    "    for author_team in year:\n",
    "        all_authors = all_authors + author_team\n",
    "\n",
    "#contains all authors' names, no duplicates\n",
    "authors_no_duplicates = list(dict.fromkeys(all_authors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 6</span></font> Creating a visualization style in order to be consistent with the visualizations later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "cell #6"
    ]
   },
   "outputs": [],
   "source": [
    "custom_style = Style(\n",
    "legend_font_size = 15,\n",
    "legend_box_size = 18,\n",
    "font_family = 'sans-serif',\n",
    "label_font_size = 14,\n",
    "major_label_font_size = 14,\n",
    "background='white',\n",
    "plot_background='white',\n",
    "foreground='black',\n",
    "foreground_strong='#53A0E8',\n",
    "foreground_subtle='#630C0D',\n",
    "opacity='0.8',\n",
    "opacity_hover='0.5',\n",
    "transition='400ms ease-in',\n",
    "colors=('#C70039', '#FFC300', '#70C700', \n",
    "        '#001EC7', '#7F3ACD', '#3ACDB4', '#EEFC11', \n",
    "        '#F2336A', '#E0BD4A', '#66A712',\n",
    "        '#1232E9', '#A883D1', '#097764', '#717800',\n",
    "        '#FE0033', '#FE6200', '#124B01'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================================================================\n",
    "\n",
    "==========================================================================================================================\n",
    "\n",
    "=========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling with Latent Dirichlet Allocation (LDA): Tuning parameters\n",
    "\n",
    "By measuring the quality measures of *perplexity* and *topic coherence*, the ideal parameters for the topic model should be found. \n",
    "\n",
    "\n",
    "**Quality measure perplexity**\n",
    "\n",
    "- Perplexity can be used to measure how good the LDA model generalizes on the text corpus (Blei et al., 2003, p. 1008)\n",
    "- the lower the perplexity, the better the model\n",
    "\n",
    "**Quality measure topic coherence** \n",
    "\n",
    "- Topic Coherence can be determined by various measurements - e.g. UMass, C_V, UCI, NPMI - which all use different measurements to calculate the coherence of topics ([Röder et al., 2015, p. 2](https://doi.org/10.1145/2684822.2685324)).\n",
    "- In this workflow, C_V is used: measurement gives values between 0 and 1, with 1 being the best coherence to be reached\n",
    "\n",
    "**Parameter topic number k**\n",
    "\n",
    "- According to [Kumar (2018)](https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/), \"[c]hoosing a ‘k’ that marks the end of a rapid growth of topic coherence usually offers meaningful and interpretable topics. Picking an even higher value can sometimes provide more granular sub-topics\". However, \"[i]f you see the same keywords being repeated in multiple topics, it’s probably a sign that the ‘k’ is too large\" (ibid).\n",
    "\n",
    "**Parameter update_every**\n",
    "\n",
    "- \"Number of documents to be iterated through for each update. Set to 0 for batch learning, > 1 for online iterative learning\" ([Rehurek, 2022b](https://radimrehurek.com/gensim/models/ldamodel.html)).\n",
    "- Here, the parameter is set to *update_every=1* as this is the default\n",
    "\n",
    "**Parameter alpha**\n",
    "\n",
    "- \"A-priori belief on document-topic distribution\" ([Rehurek, 2022a](https://radimrehurek.com/gensim/models/ldamodel.html))\n",
    "- \"Alpha is the parameter, which has the smoothing effect on the topic-document distribution and ensures that the probability of each topic in each document is not 0 throughout the entire inference procedure\" ([Du, 2022, p. 1](https://doi.org/10.5281/zenodo.6327965)). Du's study results indicate that coherence results of models deteriorate with increasing Alpha-parameter, and Du concludes that Alpha of each topic should not be higher than 1 ([Du, 2022, p. 2](https://doi.org/10.5281/zenodo.6327965)).\n",
    "\n",
    "**Parameter eta/beta**\n",
    "\n",
    "- \"[D]istributional profile of topics in each document\" ([Schöch, 2017, para. 20](http://www.digitalhumanities.org/dhq/vol/11/2/000291/000291.html)),\n",
    "- \"A-priori belief on topic-word distribution\" ([Rehurek, 2022b](https://radimrehurek.com/gensim/models/ldamodel.html))\n",
    "\n",
    "**Parameter iterations**\n",
    "- \"Maximum number of iterations through the corpus when inferring the topic distribution of a corpus\" ([Rehurek, 2022b](https://radimrehurek.com/gensim/models/ldamodel.html))\n",
    "- \"Iterations (...) essentially it controls how often we repeat a particular loop over each document. It is important to set the number of 'passes' and 'iterations' high enough\" ([Rehurek, 2022a](https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html)) to train the best LDA Topic Model\n",
    "\n",
    "\n",
    "**Parameter passes**\n",
    "- \"Number of passes through the corpus during training\" ([Rehurek, 2022b](https://radimrehurek.com/gensim/models/ldamodel.html))\n",
    "- \"Passes controls how often we train the model on the entire corpus. Another word for passes might be 'epochs'\" ([Rehurek, 2022a](https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html))."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling: Functions\n",
    "\n",
    "- Function *compute_quality_measures*:\n",
    "\n",
    "This function takes as input the created dictionary, corpus and texts on which the later Topic Models will be based, stemming from the other Jupyter Notebook. Further, it is given several other parameters which can be tuned for creating the optimal Topic Model. Those are the coherence measure to be used (*coherence*) and other parameters to be tuned such as the number of iterations(*iterations*), number of topics (*topic_optim*), values for alpha (*alpha_optim*) and beta (*eta_topim*), the number of passes (*passes*) and the frequency of evaluations (*eval_every*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 7</span></font> modeling_and_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": [
     "cell #7"
    ]
   },
   "outputs": [],
   "source": [
    "def modeling_and_quality(dictionary, corpus, texts, coherence, iterations, topic_optim, alpha_optim, eta_optim, passes, eval_every):\n",
    "\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    perplexity_values = []\n",
    "    topic_coherence_values=[]\n",
    "    model_names = []\n",
    "    \n",
    "    for topics_num in topic_optim:\n",
    "        for alpha_value in alpha_optim:\n",
    "            for eta_value in eta_optim:\n",
    "                model = LdaModel(corpus=corpus,\n",
    "                                 id2word=dictionary, \n",
    "                                 iterations=iterations, \n",
    "                                 num_topics=topics_num,\n",
    "                                 alpha=alpha_value, \n",
    "                                 eta=eta_value, \n",
    "                                 passes=passes, \n",
    "                                 eval_every=eval_every, \n",
    "                                 minimum_probability=1e-8)\n",
    "                model_list.append(model)\n",
    "                perplexity_values.append(model.log_perplexity(corpus))\n",
    "                coherencemodel = CoherenceModel(model=model, \n",
    "                                                texts=texts, \n",
    "                                                dictionary=dictionary, \n",
    "                                                corpus=corpus, \n",
    "                                                coherence=coherence, \n",
    "                                                topn=60, \n",
    "                                                window_size=150)\n",
    "                coherence_values.append(coherencemodel.get_coherence())\n",
    "                topic_coherence_values.append(coherencemodel.get_coherence_per_topic())\n",
    "                name = (str(topics_num), str(alpha_value), str(eta_value))\n",
    "                model_names.append(name)\n",
    "                name = ''\n",
    "                \n",
    "                # For controlling the progress of this very time-consuming step in the workflow, log every parameter that has been checked\n",
    "                logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "                logging.info('Topic number k: %s', topics_num)\n",
    "                logging.info('Alpha: %s', alpha_value)\n",
    "                logging.info('Beta: %s', eta_value) \n",
    "                logging.info('Coherence: %s', coherencemodel.get_coherence())\n",
    "        \n",
    "\n",
    "    return model_list, perplexity_values, coherence_values, topic_coherence_values, model_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best settings for *passes* and *iterations*:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 8</span></font> Training of the Topic Model:\n",
    "\n",
    " In order to train the model, Rehurek ([2022a](https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html)) proposes to select a random number of topics *k* and try several options for the parameters *passes* and *iterations*, while keeping all other parameters equal. Default values are *passes=1* and *iterations=50*. \n",
    " \n",
    " The tutorial proposes to use the logging function on the DEBUG level to see how many documents were converged during the training. One should opt for settings of the two parameters where most - or ideally all - documents are converged ([Rehurek, 2022a](https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html)).\n",
    "\n",
    "Here, convergence of 1202/1203 documents occurred with *k=20*, *iterations=190* and *passes=4*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": [
     "cell #8"
    ]
   },
   "outputs": [],
   "source": [
    "# initialize logging in DEBUG-mode to see the convergence of documents\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)\n",
    "\n",
    "# initializing random seed to be able to reproduce the results\n",
    "np.random.seed(3)\n",
    "\n",
    "# running the function with default values except for the topic number\n",
    "k_model_list_cv, k_perplexity_values_cv, k_coherence_values_cv, k_topic_coherence_values_cv, k_model_names_cv = modeling_and_quality(dictionary = id2word, \n",
    "                                                                                        corpus = corpus, \n",
    "                                                                                        texts = data_bigrams_trigrams, \n",
    "                                                                                        coherence = 'c_v', \n",
    "                                                                                        iterations = 190, \n",
    "                                                                                        topic_optim = [20],\n",
    "                                                                                        alpha_optim = ['auto'],\n",
    "                                                                                        eta_optim = ['auto'],\n",
    "                                                                                        passes = 4,\n",
    "                                                                                        eval_every = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best topic number *k*:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 9</span></font> After finding good settings for *passes* and *iterations*, the next step is finding the ideal topic number *k*. While trying out different values for *k* between 10 and 35 and keeping the other parameters constant, one should look for the highest coherence value and lowest perplexity value ([Kumar, 2018](https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/)).\n",
    "\n",
    "In previous experiments, topic numbers up to 70 were tried as well. However, that many topics proved to be too small and too uninterpretable for a meaningful Topic Model and therefore it was decided on trying 35 topics at the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "cell #9"
    ]
   },
   "outputs": [],
   "source": [
    "topic_optim = list(np.arange(10, 36, 1))\n",
    "\n",
    "# initializing random seed to be able to reproduce the results\n",
    "k_seed = 1\n",
    "np.random.seed(k_seed)\n",
    "\n",
    "# running the function with default values except for the topic number\n",
    "k_model_list_cv, k_perplexity_values_cv, k_coherence_values_cv, k_topic_coherence_values_cv, k_model_names_cv = modeling_and_quality(dictionary = id2word, \n",
    "                                                                                        corpus = corpus, \n",
    "                                                                                        texts = data_bigrams_trigrams, \n",
    "                                                                                        coherence = 'c_v', \n",
    "                                                                                        iterations = 190, \n",
    "                                                                                        topic_optim = topic_optim,\n",
    "                                                                                        alpha_optim = ['auto'],\n",
    "                                                                                        eta_optim = ['auto'],\n",
    "                                                                                        passes = 4,\n",
    "                                                                                        eval_every = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 10</span></font> Saving the variables for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "cell #10"
    ]
   },
   "outputs": [],
   "source": [
    "check_directory('Models/find_k_seed_' + str(k_seed) + '/')\n",
    "\n",
    "save_object('Models/find_k_seed_' + str(k_seed) + '/', 'k_model_list_cv.pckl', k_model_list_cv)\n",
    "save_object('Models/find_k_seed_' + str(k_seed) + '/', 'k_perplexity_values_cv.pckl', k_perplexity_values_cv)\n",
    "save_object('Models/find_k_seed_' + str(k_seed) + '/', 'k_coherence_values_cv.pckl', k_coherence_values_cv)\n",
    "save_object('Models/find_k_seed_' + str(k_seed) + '/', 'k_topic_coherence_values_cv.pckl', k_topic_coherence_values_cv)\n",
    "save_object('Models/find_k_seed_' + str(k_seed) + '/', 'k_model_names_cv.pckl', k_model_names_cv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 11</span></font> Plotting the results of optimizing *k* in a line graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": [
     "cell #11"
    ]
   },
   "outputs": [],
   "source": [
    "# Plotting Coherence Scores\n",
    "line_chart = pygal.Line(style=custom_style, width=1400, x_title='Number of Topics k', y_title='Coherence Score', show_legend=False)\n",
    "line_chart.title = 'Coherence Scores for Different Number of Topics k'\n",
    "line_chart.x_labels = map(str, range(10, 36))\n",
    "line_chart.add('Coherence c_v', k_coherence_values_cv)\n",
    "line_chart.render_to_file('Models/find_k_seed_' + str(k_seed) + '/k_Coherence.svg')\n",
    "\n",
    "# Plotting Perplexity Scores\n",
    "line_chart = pygal.Line(style=custom_style, width=1400, x_title='Number of Topics k', y_title='Perplexity Score', show_legend=False)\n",
    "line_chart.title = 'Perplexity Scores for Different Number of Topics k'\n",
    "line_chart.x_labels = map(str, range(10, 36))\n",
    "line_chart.add('Perplexity', k_perplexity_values_cv)\n",
    "line_chart.render_to_file('Models/find_k_seed_'+ str(k_seed)+'/k_Perplexity.svg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha and Beta Parameter Optimization with Optimal *k*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 12</span></font> Conducting another Topic Modeling Process with the optimal number for *k* from the training above. Now, the focus lies on the parameters *alpha* and *eta*, which can take on float values as well as string values. In the following, a mixture over several floats as well as strings is created, which is then given to the function *modeling_and_quality* in order to iterate over those varying values. The best *alpha* and *beta* values are again indicated by a high coherence and low perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "cell #12"
    ]
   },
   "outputs": [],
   "source": [
    "a_ints = list(np.arange(0.01, 1, 0.3))\n",
    "a_strings = ['symmetric', 'asymmetric', 'auto']\n",
    "alpha = a_ints + a_strings\n",
    "\n",
    "e_ints = list(np.arange(0.01, 1, 0.3))\n",
    "e_strings = ['symmetric', 'auto']\n",
    "eta = e_ints + e_strings\n",
    "\n",
    "# initializing random seed to be able to reproduce the results\n",
    "seed = 3\n",
    "np.random.seed(seed)\n",
    "topic_number_k = 32\n",
    "\n",
    "# running the function to find the optimal combination of parameters\n",
    "model_list_cv, perplexity_values_cv, coherence_values_cv, topic_coherence_values_cv, model_names_cv = modeling_and_quality(dictionary=id2word, \n",
    "                                                                                                                         corpus=corpus, \n",
    "                                                                                        texts=data_bigrams_trigrams, \n",
    "                                                                                        coherence='c_v', \n",
    "                                                                                        iterations = 190,\n",
    "                                                                                        topic_optim = [topic_number_k],                                                                                         \n",
    "                                                                                        alpha_optim = alpha,\n",
    "                                                                                        eta_optim = eta,\n",
    "                                                                                        passes = 4,\n",
    "                                                                                        eval_every=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 13</span></font> Saving the variables created while optimizing the parameters *alpha* and *beta*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "cell #13"
    ]
   },
   "outputs": [],
   "source": [
    "check_directory('Models/' + 'k_' + str(topic_number_k) + '_seed_' + str(seed)+ '/')\n",
    "\n",
    "save_object('Models/' + 'k_' + str(topic_number_k) + '_seed_' + str(seed)+ '/', 'model_list.pckl', model_list_cv)\n",
    "save_object('Models/' + 'k_' + str(topic_number_k) + '_seed_' + str(seed)+ '/', 'perplexity_values.pckl', perplexity_values_cv)\n",
    "save_object('Models/' + 'k_' + str(topic_number_k) + '_seed_' + str(seed)+ '/', 'coherence_values.pckl', coherence_values_cv)\n",
    "save_object('Models/' + 'k_' + str(topic_number_k) + '_seed_' + str(seed)+ '/', 'topic_coherence_values.pckl', topic_coherence_values_cv)\n",
    "save_object('Models/' + 'k_' + str(topic_number_k) + '_seed_' + str(seed)+ '/', 'model_names.pckl', model_names_cv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 14</span></font> Plotting the results of the runs finding the optimal *alpha* and *beta* parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": [
     "cell #14"
    ]
   },
   "outputs": [],
   "source": [
    "topic_number_k = 32\n",
    "seed = 3\n",
    "# Plotting Coherence Scores\n",
    "line_chart = pygal.Line(style=custom_style, width=1600, x_title='Index of Trained Models', y_title='Coherence Score', show_legend=False)\n",
    "line_chart.title = 'Coherence Scores for Different Models with Optimized Alpha and Beta Values'\n",
    "line_chart.x_labels = map(str, range(0, 42))\n",
    "line_chart.add('Coherence c_v', coherence_values_cv)\n",
    "line_chart.render_to_file('Models/'+ 'k_' + str(topic_number_k) + '_seed_' + str(seed)+ '/' + 'Coherence.svg')\n",
    "\n",
    "# Plotting Perplexity Scores\n",
    "line_chart = pygal.Line(style=custom_style, width=1600, x_title='Index of Trained Models', y_title='Perplexity Score', show_legend=False)\n",
    "line_chart.title = 'Perplexity Scores for Different Models with Optimized Alpha and Beta Values'\n",
    "line_chart.x_labels = map(str, range(0, 42))\n",
    "line_chart.add('Perplexity', perplexity_values_cv)\n",
    "line_chart.render_to_file('Models/'+ 'k_' + str(topic_number_k) + '_seed_' + str(seed)+ '/' + 'Perplexity.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "### Determining the optimal model for further use:\n",
    "\n",
    "- Function *get_topic_coherences*:\n",
    "\n",
    "This function takes as input the list of topic coherence values and the index of the model one is interested in, so that the coherences of the single topics in one certain model can be printed out, e.g. for analysis.\n",
    "\n",
    "- Function *get_model_info*:\n",
    "\n",
    "The function takes an index as input as well as the lists of model names, models, coherence values, perplexity values and topic coherence values. In combination with the used index, those lists are used to log the most important information about the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 15</span></font> get_topic_coherences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "cell #15"
    ]
   },
   "outputs": [],
   "source": [
    "def get_topic_coherences(topic_coherence_values_cv, index_best_model):\n",
    "    \n",
    "    coherences = []\n",
    "    i = 1\n",
    "    for value in topic_coherence_values_cv[index_best_model]:\n",
    "        coherences.append((i, round(value, 2)))\n",
    "        i +=1 \n",
    "        \n",
    "    return coherences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 16</span></font> get_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "cell #16"
    ]
   },
   "outputs": [],
   "source": [
    "def get_model_info(selected_index, model_names, model_list, coherence_values, perplexity_values, topic_coherence_values):\n",
    "    \n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    \n",
    "    logging.info('Index of the selected model: %s', selected_index)\n",
    "    logging.info('Model name (k, alpha, beta parameters): %s', model_names[selected_index])\n",
    "    logging.info('Number of topics in the selected model: %s', model_list[selected_index].num_topics)\n",
    "    logging.info('Coherence of the selected Topic Model: %s', coherence_values[selected_index])\n",
    "    logging.info('Perplexity value: %s', perplexity_values[selected_index])\n",
    "    logging.info('Topic coherences: %s \\n', get_topic_coherences(topic_coherence_values, selected_index)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 17</span></font> Reopening the models with *k = 32* and *seed = 3* if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "cell #17"
    ]
   },
   "outputs": [],
   "source": [
    "model_list_cv = open_variable('Models/k_32_seed_3/', 'model_list.pckl')\n",
    "coherence_values_cv = open_variable('Models/k_32_seed_3/', 'coherence_values.pckl')\n",
    "topic_coherence_values_cv = open_variable('Models/k_32_seed_3/', 'topic_coherence_values.pckl')\n",
    "model_names_cv = open_variable('Models/k_32_seed_3/', 'model_names.pckl')\n",
    "perplexity_values_cv = open_variable('Models/k_32_seed_3/', 'perplexity_values.pckl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 18</span></font> Choosing the optimal Topic Model:\n",
    "\n",
    "Inspecting the models with the highest coherences and selecting one of the models for further use. The highest coherence in this list of models is approximately 0.5, as shown in the created visualizations. Thus, to somehow structure the process of finding a meaningful model, a threshold of coherence = 0.475 was chosen to filter the models firstly according to their coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "cell #18"
    ]
   },
   "outputs": [],
   "source": [
    "possible_models = []\n",
    "for value in coherence_values_cv:\n",
    "    if value > 0.475:\n",
    "        selected_index = coherence_values_cv.index(value)\n",
    "        possible_models.append(selected_index)\n",
    "        get_model_info(selected_index, \n",
    "                       model_names_cv, \n",
    "                       model_list_cv, \n",
    "                       coherence_values_cv, \n",
    "                       perplexity_values_cv, \n",
    "                       topic_coherence_values_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 19</span></font> Visualizing and saving the generated models with pyLDAvis, so that the optimal model can be chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "cell #19"
    ]
   },
   "outputs": [],
   "source": [
    "for model in possible_models:\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis = pyLDAvis.gensim_models.prepare(model_list_cv[model], corpus, id2word)\n",
    "    name_visualization = 'Visualization_model_index_' + str(model) + '.html'\n",
    "    pyLDAvis.save_html(vis, 'Models/' + name_visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 20</span></font> Optimal model:\n",
    "\n",
    "After close inspection, the model with index = 5 seems to fit the purposes best. Thus, it is determined as the optimal model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "cell #20"
    ]
   },
   "outputs": [],
   "source": [
    "optimal_model = model_list_cv[5]\n",
    "final_num_topics = optimal_model.num_topics\n",
    "optimal_model.save('Models/optimal_model_k32.model', 'w')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================================================================\n",
    "\n",
    "==========================================================================================================================\n",
    "\n",
    "=========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 1: Topics of the DHd\n",
    "\n",
    "### *Which topics can be found in the abstracts from DHd conferences between 2014 and 2023 with Topic Modeling?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ1: Functions\n",
    "\n",
    "\n",
    "- Function *find_document_topics*:\n",
    "\n",
    "Considering each document from the corpus, this function initially determines which topic has the highest probability in the specific text. In addition, it also extracts the whole topic probability distribution for each of the documents. The function returns a dictionary which contains the text ids as keys and the number of the most prominent topic as values and a list containing all topic probabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 21</span></font> find_document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "cell #21"
    ]
   },
   "outputs": [],
   "source": [
    "def find_document_topics(corpus, model):\n",
    "    \n",
    "    topics_per_document = []\n",
    "    salient_topics = {}\n",
    "    i = 0\n",
    "\n",
    "    for document in corpus:\n",
    "        doc_topics = model.get_document_topics(document)\n",
    "        \n",
    "        #finding the most salient topic in each text\n",
    "        most_salient_topics = max(doc_topics, key=itemgetter(1))\n",
    "        salient_topic_number, salient_topic_probability = most_salient_topics\n",
    "        salient_topics[i] = salient_topic_number +1\n",
    "        \n",
    "        #saving the complete topic distribution of each text in a list\n",
    "        probabilities = []\n",
    "        for topic in doc_topics:\n",
    "            topic_num, probability = topic\n",
    "            probabilities.append(probability)\n",
    "        topics_per_document.append(probabilities)\n",
    "        i += 1    \n",
    "    \n",
    "    return salient_topics, topics_per_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ1: Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 22</span></font> If necessary, the optimal model can be loaded from the folder with the following line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "cell #22"
    ]
   },
   "outputs": [],
   "source": [
    "optimal_model = LdaModel.load('Models/optimal_model_k32.model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 23</span></font> Using the function *find_document_topics* to find out which texts have a certain topic as prevalent topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "cell #23"
    ]
   },
   "outputs": [],
   "source": [
    "main_topics, topics_per_document = find_document_topics(corpus, optimal_model)\n",
    "\n",
    "for item in main_topics.items():\n",
    "    key, value = item\n",
    "    if value == 1:\n",
    "        logging.info('%s %s', key, textnames[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 24</span></font> Dictionary of all topic numbers and interpreted themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "cell #24"
    ]
   },
   "outputs": [],
   "source": [
    "topics = {1: 'General Research Process and Challenges',\n",
    "2: 'Research Objects in DH',\n",
    "3: 'Machine Translation',\n",
    "4: 'Automatic Text Annotation',\n",
    "5: 'Text Genres',\n",
    "6: 'Multimodality and Multimedia',\n",
    "7: 'Structure and Schedule of Projects',\n",
    "8: 'Geography',\n",
    "9: 'Literary Studies',\n",
    "10: 'Linguistics and Discourse Analysis',\n",
    "11: 'Interdisciplinarity and Science',\n",
    "12: 'Data Models and Data Management',\n",
    "13: 'Mass Digitization Projects',\n",
    "14: 'Compilation of Corpora and Data Sustainability',\n",
    "15: 'Data Bases and Research Infrastructures',\n",
    "16: 'XML',\n",
    "17: 'Automatic Detection of Persons, Visual Objects, Qualities',\n",
    "18: 'Authorship Attribution',\n",
    "19: 'Network Analysis',\n",
    "20: 'Classification',\n",
    "21: 'Large Textual Resources',\n",
    "22: 'Drama and Comparative Drama Analysis',\n",
    "23: 'Art History',\n",
    "24: 'Music and Computized Music Annotation',\n",
    "25: 'OCR',\n",
    "26: 'Transcription',\n",
    "27: 'Morphology, Lexicography, Archaeology',\n",
    "28: 'Research Softwares and Tools',\n",
    "29: 'Collocations and Metaphors',\n",
    "30: '3D Reconstruction',\n",
    "31: 'Topic Modeling',\n",
    "32: 'Font Recognition, Figures in Plays'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================================================================\n",
    "\n",
    "==========================================================================================================================\n",
    "\n",
    "=========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 2: Topic Trends\n",
    "\n",
    "### *How have the topics been changing throughout the years - which trends are perceptible?*\n",
    "\n",
    "\n",
    "Mann-Kendall (MK) Test:\n",
    "\n",
    "- MK Test analyzes whether there is a trend in a topic's appearance over time: increasing, decreasing, no trend (Chen et al., 2020; [Mann, 1945](https://www.jstor.org/stable/1907187))\n",
    "- results are statistically significant if *p <= 0.05*\n",
    "- results are highly statistically significant if *p <= 0.01*\n",
    "- [Further Information on Mann-Kendall Test:](https://www.geeksforgeeks.org/how-to-perform-a-mann-kendall-trend-test-in-python/) (geetansh044, n.d.)\n",
    "\n",
    "\n",
    "### RQ2: Functions\n",
    "\n",
    "- Function *calculate_topic_average*:\n",
    "\n",
    "This function takes the list of indexes for each year's corpus as well as the lists of topics per text as input. The latter one contains a list of probabilities for every topic for every document in the corpus. On the basis of those probabilites and separated by the DHd year the documents belong to, the average probability of each topic within each conference year is calculated. Those averages are then stored in another list, which is returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 25</span></font> calculate_topic_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "cell #25"
    ]
   },
   "outputs": [],
   "source": [
    "def calculate_topic_average(indexes, topics_per_document):\n",
    "    \n",
    "    averages_per_topic_per_year = []\n",
    "    i = 0 \n",
    "    j = 1\n",
    "    \n",
    "    while i < int(len(indexes)-1):\n",
    "        all_probabilities = []\n",
    "        for text in topics_per_document[indexes[i]:indexes[j]]:\n",
    "            all_probabilities.append(text)\n",
    "        # dividing the sum of all first, second, third... values by the number of values to get the average of all n topics for one year\n",
    "        averages_per_topic = ((np.sum(all_probabilities, axis=0)/len(all_probabilities))*100)\n",
    "        averages_per_topic_per_year.append(averages_per_topic)\n",
    "        i +=1\n",
    "        j += 1\n",
    "        \n",
    "    return averages_per_topic_per_year"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ2: Main\n",
    "\n",
    "<span style='color:violet'><font size='2'>Cell 26</span></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "cell #26"
    ]
   },
   "outputs": [],
   "source": [
    "# using the list of names of documents for each year to count how many documents belong to one year\n",
    "topic_averages = calculate_topic_average(indexes, topics_per_document)\n",
    "\n",
    "# creating a dataframe which shows the average probability of a topic in each year\n",
    "df_author_analysis = pd.DataFrame(topic_averages, index = filenames).T\n",
    "df_author_analysis['Mean'] = df_author_analysis.mean(axis=1)\n",
    "\n",
    "# conducting the Mann-Kendall Test on the values of each of the topics, excluding the 'mean' column\n",
    "mk_test = []\n",
    "for i in range(0, final_num_topics):\n",
    "    mk_test.append(mk.original_test(df_author_analysis.values[i][:-1]))\n",
    "mk_results = pd.DataFrame(mk_test)\n",
    "\n",
    "# joining the averages-DF and the Mann-Kendall Test-DF in order to have complete csv-file\n",
    "mk_df = df_author_analysis.join(mk_results)\n",
    "# rename columns so that topics are 1-22 and not 0-21 (similar in all other uses)\n",
    "mk_df.index = list(topics.values())\n",
    "mk_df.round(2).to_csv('Figures/RQ2/RQ2__Mann-Kendall.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 27</span></font> Creating several line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "cell #27"
    ]
   },
   "outputs": [],
   "source": [
    "# dividing up the number of topics in order to plot understandable graphs \n",
    "parts = [0, round(final_num_topics*0.25), round(final_num_topics*0.5), round(final_num_topics*0.75), final_num_topics]\n",
    "\n",
    "for k in range(len(parts)-1):\n",
    "    line_chart = pygal.Line(style=custom_style, value_font_size=40, x_title = 'Years Observed', \n",
    "                            y_title = 'Average Probability in %', truncate_legend = 25, \n",
    "                            legend_at_bottom = True, width = 1000)\n",
    "    line_chart.title = 'Average Probabilities of Topics over the Years'\n",
    "    line_chart.x_labels = filenames\n",
    "    line_chart.font_size = 40\n",
    "    for i in range(parts[k], parts[k+1]):\n",
    "        line_chart.add((list(topics.values())[i]), df_author_analysis.round(2).values[i][:-1])\n",
    "    \n",
    "    name = 'Figures/RQ2/RQ2__TopicProbabilitiesPerYear_' + str(parts[k]+1) + '-' + str((parts[k+1])) + '.svg'\n",
    "    line_chart.render_to_file(name) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================================================================\n",
    "\n",
    "==========================================================================================================================\n",
    "\n",
    "=========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 3: Topic Similarity\n",
    "\n",
    "### *Which topics appear together frequently in one abstract and therefore have a high topic similarity?*\n",
    "\n",
    "### RQ3: Functions\n",
    "\n",
    "- Function *create_dendrogram*:\n",
    "\n",
    "The function has the purpose to create a dendrogram for hierarchical clustering. It is given the topic vectors for each year and for all years as input, as well as titles for x-axis and the whole visualization, labels for the leaves and the resulting file name. For the clustering process itself, the library scipy is used with its objects *cluster.hierarchy.dendrogram* and *.linkage*. *.linkage* does the actual clustering by first calculating the euclidean distances between the vectors and then using the ward method to do the clustering itself. Then, *.dendrogram* is used for visualizing the dendrogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 28</span></font> create_dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "cell #28"
    ]
   },
   "outputs": [],
   "source": [
    "def create_dendrogram(vector, xlabel, plot_title, color_threshold, leaf_labels, filename):\n",
    "    \n",
    "    plt.ioff()\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    plt.xlabel(xlabel, fontsize = 26)  \n",
    "    plt.title(plot_title, fontsize = 26) \n",
    "    set_link_color_palette(['#C70039', '#FFC300', '#70C700', '#001EC7', '#7F3ACD', '#3ACDB4', '#EEFC11'])\n",
    "    dend = dendrogram(linkage(vector, \n",
    "                              metric='euclidean', \n",
    "                              method='ward'), \n",
    "                      color_threshold = color_threshold, \n",
    "                      labels = leaf_labels, \n",
    "                      leaf_font_size = 26, \n",
    "                      orientation = 'right')\n",
    "    plt.tick_params(axis='x', which='major', labelsize=18)\n",
    "    plt.savefig(filename, format='svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ3: Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 29</span></font> Creating a dendrogram with the topic distances for every year observed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "cell #29"
    ]
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(indexes)-1):\n",
    "    # separating the data according to the conference year the texts belong to\n",
    "    df_topics_per_document = topics_per_document[indexes[i]:indexes[i+1]]\n",
    "    \n",
    "    # creating and transposing DataFrame to easily extract each first, second, third value in the lists\n",
    "    df_topics_per_year = pd.DataFrame(data=df_topics_per_document).T\n",
    "    \n",
    "    # topic_vectors contains a list for each year\n",
    "    # each list contains the probability of the respective topic for each text of the year, therefore each list is as long as the indexes indicate\n",
    "    # therefore, topic_vectors_years[0] contains topic 0's probabilities from all texts from the analyzed year, topic_vectors[1] contains topic 1's probabilities from the year\n",
    "    topic_vectors_years = []\n",
    "    # for j in range(0, final_num_topics):\n",
    "    for j in range(0, final_num_topics):\n",
    "        topic_vectors_years.append(df_topics_per_year.iloc[j].values)\n",
    "    \n",
    "    create_dendrogram(topic_vectors_years, \n",
    "                      '', \n",
    "                      filenames[i]+': Hierarchical Clustering of All Topics Based on Euclidean Distance', \n",
    "                      2,\n",
    "                       list(topics.values()),\n",
    "                       'Figures/RQ3/RQ3__Clustering'+ filenames[i]+'.svg')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 30 </span></font> Creating a dendrogram with the topic distances for all years combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "cell #30"
    ]
   },
   "outputs": [],
   "source": [
    "# creating DataFrame to easily extract each first, second, third value in the lists\n",
    "df_topics_all_years = pd.DataFrame(data = topics_per_document).T\n",
    "\n",
    "topic_vectors_total = []\n",
    "# basically same operations as above, but without splitting by years\n",
    "for i in range(0, final_num_topics):\n",
    "    topic_vectors_total.append(df_topics_all_years.iloc[i].values)\n",
    "\n",
    "create_dendrogram(topic_vectors_total, \n",
    "                  '', \n",
    "                  '2014-2023: Hierarchical Clustering of Topics Based on Euclidean Distance', \n",
    "                  2,\n",
    "                  list(topics.values()),\n",
    "                  'Figures/RQ3/RQ3__Clustering_AllYears.svg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================================================================\n",
    "\n",
    "==========================================================================================================================\n",
    "\n",
    "=========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 4: Keywords and Methods\n",
    "### *With regard to the use of different scientific methods and keywords, which developments are perceptible?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of keywords used in the xml files of the DHd conferences: \\<keywords scheme=\"ConfTool\" n=\"keywords\"> and \\<keywords scheme=\"ConfTool\" n=\"topics\">. The former may be used by authors to freely annotate their xml file with words which they want to be in the metadata, while the latter one only allows for a selection of keywords.\n",
    "From 2016 on, authors to the conference could select keywords to be used in the xml file to their contribution. The list of keywords is 74 items long, out of which six can currently be selected for the xml file. In 2016 and 2017, this restriction did not exist, so that authors could select more than six keywords for the metadata. The full list of usable keywords is called 'conf_tool_methods' and will be used in the following.\n",
    "\n",
    "\n",
    "### RQ4: Functions\n",
    "\n",
    "- Function *count_keywords*:\n",
    "\n",
    "This function is the first to be called for RQ4 and takes two lists as input arguments. The first one contains all freely-assigned keywords which were used in all xml documents from 2016 until 2023. This list is then used to create a dictionary for counting the used methods. First, all values to the keys, which are the methods' names, are set to 0. Then the second list provided will be iterated over and the values of the methods are added to. This happens for each DHd year separately, so that the sorted list returned by *count_keywords* provides an overview of which methods were used how often in which year.\n",
    "\n",
    "- Function *calculate_relative_count*:\n",
    "\n",
    "The function takes as input the keywords extracted in the previous function, the sorted list of counted keywords from *count_keywords* as well as a list stating how many xml files are in each conference year's corpus. The function's purpose is to calculate how often each extracted keyword is used in each year in relation to the corpus size. Taking the corpus size into account is important as the number of documents in the different corpora varies strongly, so that the numbers would be distorted if corpus size was not taken into account.\n",
    "\n",
    "- Function *information_on_keywords*:\n",
    "\n",
    "This function calls on the other two functions sequentially and returns the relative count of use of keywords.\n",
    "\n",
    "- Function *chart_and_csv*:\n",
    "\n",
    "*chart_and_cv* takes as input data calculated beforehand as well as titles for the resulting output. It turns the given data into a line chart containing only a small amount of selected data as well as a csv file that contains all data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 31</span></font> count_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": [
     "cell #31"
    ]
   },
   "outputs": [],
   "source": [
    "def count_keywords(complete_list, year_list):\n",
    "    # for each year, a large list of all possible, freely annotated keywords is set up and the count for each of the keywords is set to 0\n",
    "    # if the method appears in the specific year's list, +1 will be added to the count\n",
    "\n",
    "    counted_keywords_per_year = []\n",
    "    for year in year_list:\n",
    "        dict = {}\n",
    "        for method in complete_list:\n",
    "            dict[method] = 0\n",
    "        for method in year:\n",
    "            dict[method] += 1\n",
    "        # sorting the dict according to the count, so that the item with the highest count comes first\n",
    "        sorted_dict = sorted(dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        counted_keywords_per_year.append(sorted_dict)\n",
    "    \n",
    "    return counted_keywords_per_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 32</span></font> calculate_relative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": [
     "cell #32"
    ]
   },
   "outputs": [],
   "source": [
    "def calculate_relative_count(complete_list, absolute_count_keywords, number_xml_docs):\n",
    "    \n",
    "    # for the used keywords, it is looked at how often they appear in each year's corpus\n",
    "    # then, that count will be divided by the total number of texts in that corpus, which results in a proportional frequency of the keyword to the corpus size \n",
    "    \n",
    "    relative_dict = {}\n",
    "    for item in complete_list:\n",
    "        item_count = []\n",
    "        i = 0\n",
    "        for year in absolute_count_keywords:\n",
    "            \n",
    "            for tuple in year:\n",
    "                name, count = tuple\n",
    "                if name == item:\n",
    "                    item_count.append(round((count/number_xml_docs[i])*100, 2))\n",
    "            i += 1\n",
    "        relative_dict[item] = item_count\n",
    "\n",
    "    return relative_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 33</span></font> retrieve_information_on_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": [
     "cell #33"
    ]
   },
   "outputs": [],
   "source": [
    "def retrieve_information_on_keywords(total_list, used_keywords_list, number_xml_docs):\n",
    "    \n",
    "    absolute_count_keywords = count_keywords(total_list, used_keywords_list)\n",
    "    relative_count_keywords = calculate_relative_count(total_list, absolute_count_keywords, number_xml_docs)\n",
    "    \n",
    "    return absolute_count_keywords, relative_count_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 34</span></font> chart_and_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": [
     "cell #34"
    ]
   },
   "outputs": [],
   "source": [
    "def chart_and_csv(chart_title, filenames_xml, chart_filename, all_relative_counts, csv_filename):\n",
    "    \n",
    "    # creating a plot for visualisation\n",
    "    line_chart = pygal.Line(truncate_legend=-1, \n",
    "                            x_title='Years Observed', \n",
    "                            y_title= 'Percentage of Term Usages' + '\\n' + '(Relative to Corpus Size)', \n",
    "                            width = 1000, \n",
    "                            style = custom_style,\n",
    "                            legend_at_bottom = True)\n",
    "\n",
    "    \n",
    "    # for complete information, a csv-file is provided with all used keywords and their relative counts\n",
    "    df_keywords = pd.DataFrame(all_relative_counts.values(), index=all_relative_counts.keys(),columns=filenames_xml)\n",
    "    \n",
    "    df_keywords['Mean'] = df_keywords.mean(axis=1).round(2)\n",
    "    df_keywords = df_keywords.sort_values(by=['Mean'], ascending=False)\n",
    "    \n",
    "    if '' in df_keywords.index:\n",
    "        df_keywords = df_keywords.drop('')\n",
    "\n",
    "    df_keywords.to_csv(csv_filename)\n",
    "    \n",
    "    line_chart.title = chart_title\n",
    "    line_chart.x_labels = filenames_xml\n",
    "    for i in range(0, 10):\n",
    "        line_chart.add(df_keywords.index[i], df_keywords.iloc[i, :-1])\n",
    "    line_chart.render_to_file(chart_filename)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ4: Main"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 35</span></font> Collecting all necessary information on the keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": [
     "cell #35"
    ]
   },
   "outputs": [],
   "source": [
    "# importing the list provided, which contains all selectable options for <keywords n='keywords'>\n",
    "all_predetermined_keywords = open_list('Misc/predetermined_keywords.txt')\n",
    "\n",
    "absolute_count_free_keywords, relative_count_free_keywords = retrieve_information_on_keywords(all_freely_selectable_keywords, \n",
    "                                                                                              used_keywords_freely_selectable, \n",
    "                                                                                              number_xml_docs)\n",
    "\n",
    "absolute_count_predetermined_keywords, relative_count_predetermined_keywords = retrieve_information_on_keywords(all_predetermined_keywords, \n",
    "                                                                                                                used_keywords_predetermined, \n",
    "                                                                                                                number_xml_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 36 </span></font> Creating a line chart and csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": [
     "cell #36"
    ]
   },
   "outputs": [],
   "source": [
    "chart_and_csv('Used Terms in <keywords n=\\'keywords\\'>', filenames_xml, \n",
    "             'Figures/RQ4/RQ4__Free_ResearchMethodsPerYear.svg', relative_count_free_keywords, 'Figures/RQ4/RQ4__Free_Keywords_All.csv')\n",
    "\n",
    "chart_and_csv('Used Terms in <keywords n=\\'topics\\'>', filenames_xml, \n",
    "             'Figures/RQ4/RQ4__Predetermined_ResearchMethodsPerYear.svg', relative_count_predetermined_keywords,'Figures/RQ4/RQ4__Predetermined_Keywords_All.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================================================================\n",
    "\n",
    "==========================================================================================================================\n",
    "\n",
    "=========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 5: Authors and Networks\n",
    "\n",
    "\n",
    "### *Which researchers contribute to the conference particularly frequently with abstracts, in which teams do they contribute and how have the teams been changing?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ5: Functions - Part 1: Data Processing\n",
    "\n",
    "- Function *count_appearances_descending*:\n",
    "\n",
    "*count_appearances_descending* takes a list as input and counts how often a list item appears within the list. The function returns a sorted dictionary in which the keys with the highest values come first.\n",
    "\n",
    "- Function *rank_authors*:\n",
    "\n",
    "*rank_authors* takes as input the nested list of authors per text and per year, and turns it one large list containing every author who contributed the conference in one year. This list contains authors twice/three times if they contributed twice/three times within one conference, which is how eventually a count of every author and their contributions to the conferene is set up. The function returns a list of lists, in which the authors' names and their respective count of contributions for one year is stored. This function is necessary to set up the network nodes in a last step.\n",
    "\n",
    "- Function *find_coauthors*:\n",
    "\n",
    "The function *find_coauthors* takes the same list, *authors*, as input. Differently to *rank_authors*, however, this function uses the input list to determine the coauthors of one year. This means that it extracts the authors who worked together in one single contribution in pairs and counts how often these pairs appear within one conference year. This function prepares the data for adding edges and their weight to the network.\n",
    "\n",
    "- Function *find_new_authors*:\n",
    "\n",
    "*find_new_authors* takes the output list from *rank_authors* as input and uses it to determine which authors have contributed to one conference but not the previous one. Further, it identifies authors who have never contributed to any DHd conference. This is done by comparing the authors lists of one year with the one from the previous year(s). Those new authors are stored in a list, which is used in the setting up of the network in order to mark those new authors.\n",
    "\n",
    "- Function *convert_tuples_to_dict*:\n",
    "\n",
    "Converts a list of tuples into a dictionary where the first tuple-item is the key and the second tuple-item is the value.\n",
    "\n",
    "- Function *check_for_significant_teams*:\n",
    "\n",
    "Takes the list of the 25 most significant, i.e. most contributing authors as input and the list of coauthors per year. Iterating over these lists, the function then checks whether two of the significant authors collaborated on a conference document and saves this team of authors. \n",
    "\n",
    "- Function *count_team_appearances*:\n",
    "\n",
    "Gets the list of significant teams returned by *check_for_significant_teams* as input and counts how often each team collaborated togehter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 37</span></font> count_appearances_descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": [
     "cell #37"
    ]
   },
   "outputs": [],
   "source": [
    "def count_appearances_descending(input_list):\n",
    "    \n",
    "    count_dict = {}\n",
    "    # for each item in keyword list, check if it is alredy in dictionary\n",
    "    # if not, add and set count to 1, if yes add +1 to count\n",
    "    for item in input_list:\n",
    "        if item not in count_dict.keys():\n",
    "            count_dict[item] = 1\n",
    "        else:\n",
    "            count_dict[item] += 1\n",
    "    # sort dictionary according to highest count in the values\n",
    "    sorted_dict = sorted(count_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # return the sorted dictionary (becomes list through sorting though)\n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 38</span></font> rank_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": [
     "cell #38"
    ]
   },
   "outputs": [],
   "source": [
    "def rank_authors(authors):\n",
    "\n",
    "    all_counted_authors = []\n",
    "    for year in authors:\n",
    "        authors_list_per_year = [] \n",
    "        for team in year:\n",
    "            # create one long list of all authors of one year (not separated by author team)\n",
    "            authors_list_per_year = authors_list_per_year + team\n",
    "        all_counted_authors.append(count_appearances_descending(authors_list_per_year))\n",
    "        \n",
    "    return all_counted_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 39</span></font> find_coauthors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": [
     "cell #39"
    ]
   },
   "outputs": [],
   "source": [
    "def find_coauthors(authors):\n",
    "    \n",
    "    coauthors_per_year = []\n",
    "    for conference_year in authors:\n",
    "        coauthors_list = []\n",
    "        for document_authors in conference_year:\n",
    "            # check if text has at least two authors\n",
    "            if len(document_authors) >= 2:\n",
    "                for i in range(len(document_authors)-1):\n",
    "                    for j in range(i+1, len(document_authors), 1):\n",
    "                        coauthors_list.append((document_authors[i], document_authors[j]))              \n",
    "        dict_coauthors_count = count_appearances_descending(coauthors_list)      \n",
    "        coauthors_per_year.append(dict_coauthors_count) \n",
    "        \n",
    "    return coauthors_per_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 40</span></font> find_new_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": [
     "cell #40"
    ]
   },
   "outputs": [],
   "source": [
    "def find_new_authors(all_counted_authors):\n",
    "    \n",
    "     # returns list of people who did not participate previous DHd conferences\n",
    "    new_authors = [[]]\n",
    "    all_prev_authors = []\n",
    "    for i in range(1, len(all_counted_authors)):\n",
    "        current_year = all_counted_authors[i]\n",
    "        prev_year = authors[i-1]\n",
    "        \n",
    "        prev_authors = []\n",
    "        completely_new_authors = []\n",
    "        \n",
    "        for item in prev_year:\n",
    "            prev_authors = prev_authors + item\n",
    "        all_prev_authors = all_prev_authors + prev_authors        \n",
    "        for element in current_year:\n",
    "            name, count = element\n",
    "            if name not in all_prev_authors:\n",
    "                completely_new_authors.append(name)\n",
    "        new_authors.append(completely_new_authors)\n",
    "    \n",
    "    return new_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 41</span></font> convert_tuples_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": [
     "cell #41"
    ]
   },
   "outputs": [],
   "source": [
    "def convert_tuples_to_dict(tuple_list):\n",
    "    \n",
    "    new_dict = {}\n",
    "    for tuple in tuple_list:\n",
    "        item1, item2 = tuple\n",
    "        new_dict[item1] = item2\n",
    "\n",
    "    return new_dict   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 42</span></font> check_for_significant_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": [
     "cell #42"
    ]
   },
   "outputs": [],
   "source": [
    "def check_for_significant_teams(list_significant_DHumanists, coauthors):\n",
    "    \n",
    "    teams = []\n",
    "    for i in range(len(list_significant_DHumanists)-1):\n",
    "        for j in range(i+1, len(list_significant_DHumanists), 1):\n",
    "            k = 0\n",
    "            for year in coauthors:\n",
    "                for team in year:\n",
    "                    #check if team of authors consists of only the most significant authors (i.e. the 25 most contributing ones)\n",
    "                    if list_significant_DHumanists[i][0] in team[0][0] and list_significant_DHumanists[j][0] in team[0][1] or list_significant_DHumanists[i][0] in team[0][1] and list_significant_DHumanists[j][0] in team[0][0]:\n",
    "                            teams.append(team)\n",
    "                k += 1\n",
    "                \n",
    "    return teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 43</span></font> count_team_appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": [
     "cell #43"
    ]
   },
   "outputs": [],
   "source": [
    "def count_team_appearances(teams):\n",
    "\n",
    "    teams_dict = {}\n",
    "    for element in teams:\n",
    "        author_team, team_count = element        \n",
    "        if author_team not in teams_dict:\n",
    "            teams_dict[author_team] = team_count\n",
    "        else: \n",
    "            teams_dict[author_team] += team_count\n",
    "\n",
    "    return teams_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ5: Functions - Part 2: Network \n",
    "\n",
    "- Function *determine_node_shape*:\n",
    "\n",
    "Depending on how often the author contributed to the DHd conference in the respective year, i.e. whether they are a very frequent author or not, this function returns a string which then determines the author's node shape in the final network. \n",
    "\n",
    "- Function *add_nodes*:\n",
    "\n",
    "Creates a node for every author that contributed to the DHd in that specific year. Depending on how often that author contributed to the conference in the form of writing an abstract, the shape of the node is determined. \n",
    "\n",
    "- Function *change_color_new_authors*:\n",
    "\n",
    "For every author appearing in the new_authors list, the node color is changed from pink to orange, so that they can be clearly distinguished in the network.\n",
    "\n",
    "- Function *determine_edge_color*:\n",
    "\n",
    "The function *determine_edge_color* is applied while setting up the network. Based on the variable *coauthor-count*, which is determined by the function *find_coauthors*, this function determines the color of the network's edges depending on how often the respective authors have worked together in on conference year. \n",
    "\n",
    "- Function *add_edges*:\n",
    "\n",
    "For every team of coauthors, the edges within the nodes are added by referring to the authors' nodes by their names. The edge colors are determined by how often the respective authors collaborated in that DHd year, which precisely happens in the function *determine_edge_color*.\n",
    "\n",
    "- Function *generate_html_file*:\n",
    "\n",
    "Generates an html file containing all the nodes and edges created previously. Additionally, a legend is added to the html, so that the colors and shapes within the network can be understood. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 44</span></font> determine_node_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": [
     "cell #44"
    ]
   },
   "outputs": [],
   "source": [
    "def determine_node_shape(total_count, topcount):\n",
    "    \n",
    "    if total_count == topcount:\n",
    "        return 'star'\n",
    "    else:\n",
    "        return 'dot'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 45</span></font> add_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": [
     "cell #45"
    ]
   },
   "outputs": [],
   "source": [
    "def add_nodes(all_counted_authors, i):\n",
    "    \n",
    "    top_name, top_count = all_counted_authors[i][0]\n",
    "    for author in all_counted_authors[i]:\n",
    "        name, total_count = author\n",
    "        title = (name, total_count)\n",
    "        g.add_node(name, \n",
    "                title=title, \n",
    "                label=name, \n",
    "                size=(total_count*10), \n",
    "                # pink\n",
    "                color='#C70039',\n",
    "                borderWidth=1, \n",
    "                borderWidthSelected=3,\n",
    "                # determine the nodes' shape according to whether author is top author with most contributions in that year (==star) or not (==dot)\n",
    "                shape = determine_node_shape(total_count, top_count))\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 46</span></font> change_color_new_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": [
     "cell #46"
    ]
   },
   "outputs": [],
   "source": [
    "def change_color_new_authors(new_authors, i):\n",
    "       \n",
    "    if len(new_authors[i]) > 0:\n",
    "        for author in new_authors[i]:\n",
    "            g.get_node(author)['color'] = 'orange'\n",
    "        \n",
    "    return len(new_authors[i])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 47</span></font> determine_edge_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": [
     "cell #47"
    ]
   },
   "outputs": [],
   "source": [
    "def determine_edge_color(coauthor_count):\n",
    "      \n",
    "      # function to determine the color of the network's edges, depending on how often authors worked together in that year\n",
    "      # dark blue\n",
    "      if coauthor_count >= 3:\n",
    "            return '#360BFA'\n",
    "      # light blue\n",
    "      elif coauthor_count == 2:\n",
    "            return '#6CADFB'\n",
    "      # turquoise\n",
    "      else: \n",
    "        return '#1FA3B5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 48</span></font> add_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": [
     "cell #48"
    ]
   },
   "outputs": [],
   "source": [
    "def add_edges(coauthors_per_year, i):\n",
    "    \n",
    "    for item in coauthors_per_year[i]:\n",
    "        name1 = item[0][0]\n",
    "        name2 = item[0][1]\n",
    "        coauthor_count = item[1]\n",
    "    \n",
    "        # edge color depending on how often authors worked togehter\n",
    "        g.add_edge(name1, name2, \n",
    "                    width=(coauthor_count),\n",
    "                    title=(coauthor_count),\n",
    "                    color = determine_edge_color(coauthor_count))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 49</span></font> generate_html_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": [
     "cell #49"
    ]
   },
   "outputs": [],
   "source": [
    "def generate_html_file(filenames_xml, i):\n",
    "    \n",
    "    # opening the provided HTML code which has to be added to the network html file\n",
    "    with open('Misc/LegendHTML.txt', 'r', encoding='utf-8') as legend:\n",
    "        html_addition = legend.read()\n",
    "    \n",
    "    # writing an html-file\n",
    "    html = g.generate_html()\n",
    "    name = 'Figures/RQ5/RQ5__Authors_Networks_' + str(filenames_xml[i][-4:]) + '.html'\n",
    "    \n",
    "    with open(str(name), mode='w', encoding='utf-8') as fp:        \n",
    "        # finding the proper place in the html document and inserting the additional markup for legend\n",
    "        find = re.search(r'<div id=\"mynetwork\" class=\"card-body\"></div>', html)\n",
    "        end = find.end()+1\n",
    "\n",
    "        html = html[:end] + html_addition + html[end:]   \n",
    "        fp.write(html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ5: Main\n",
    "\n",
    "<span style='color:violet'><font size='2'>Cell 50</span></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": [
     "cell #50"
    ]
   },
   "outputs": [],
   "source": [
    "#needed for network\n",
    "all_counted_authors = rank_authors(authors)\n",
    "coauthors_per_year = find_coauthors(authors)\n",
    "new_authors = find_new_authors(all_counted_authors)\n",
    "\n",
    "#needed for cooccurrence matrix\n",
    "most_significant_DHumanists_list = count_appearances_descending(all_authors)[:25]\n",
    "most_significant_DHumanists_dict = convert_tuples_to_dict(most_significant_DHumanists_list)\n",
    "significant_DH_teams = check_for_significant_teams(most_significant_DHumanists_list, coauthors_per_year)\n",
    "significant_teams_count = count_team_appearances(significant_DH_teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 51</span></font> Creating the networks:\n",
    "\n",
    "The nodes have to be added as well as the edges and their weights. In the end, the general algorithm of the network as well as some other parameters are defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": [
     "cell #51"
    ]
   },
   "outputs": [],
   "source": [
    "# implementing the statistics for each year\n",
    "statistics_completely_new_authors = []\n",
    "\n",
    "i = 0\n",
    "for year in filenames_xml:\n",
    "      \n",
    "  # implementing the network itself for each year\n",
    "  g = Network(height='600px', width='100%', cdn_resources='remote', select_menu=True, font_color='black', filter_menu=True, neighborhood_highlight=True)\n",
    "  nxg = nx.complete_graph(0)\n",
    "  g.from_nx(nxg)\n",
    "  \n",
    "  # adding nodes and edges, determining colors and shapes, writing html file\n",
    "  add_nodes(all_counted_authors, i)\n",
    "  number_new_authors = change_color_new_authors(new_authors, i)\n",
    "  statistics_completely_new_authors.append(number_new_authors)\n",
    "  add_edges(coauthors_per_year, i)\n",
    "  generate_html_file(filenames_xml, i)\n",
    "  \n",
    "  i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 52</span></font> Creating DataFrames:\n",
    "\n",
    "DataFrames for the collaborations of significant authors and for a statistic of (new) authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": [
     "cell #52"
    ]
   },
   "outputs": [],
   "source": [
    "#creating a dataFrame that contains the names of significant authors and the times they collaborated\n",
    "cooccurrence_matrix = pd.DataFrame(index = most_significant_DHumanists_dict.keys(), columns = most_significant_DHumanists_dict.keys())\n",
    "cooccurrence_matrix['Total contributions to conference'] = most_significant_DHumanists_dict.values()\n",
    "\n",
    "#determining the right cell to enter the count of the team\n",
    "for duo in significant_teams_count:\n",
    "    cooccurrence_matrix.loc[duo[0], duo[1]] = significant_teams_count[duo]\n",
    "cooccurrence_matrix.fillna(0).to_csv('Figures/RQ5/RQ5__Cooccurrence_Matrix_Significant_Authors.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 53</span></font> DataFrame and csv file for analyzing new authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": [
     "cell #53"
    ]
   },
   "outputs": [],
   "source": [
    "total_number_authors = []\n",
    "for year in all_counted_authors:\n",
    "     total_number_authors.append(len(year))\n",
    "     \n",
    "d = {'Total Number of Contributing Authors': total_number_authors,\n",
    "     'New Authors': statistics_completely_new_authors}\n",
    "\n",
    "df_author_analysis = pd.DataFrame(data = d, index = filenames_xml)\n",
    "df_author_analysis['% of New Authors'] = round(df_author_analysis['New Authors'].div(df_author_analysis['Total Number of Contributing Authors'])*100 , 2)\n",
    "df_author_analysis['Average Number of Authors Per Text'] = round(df_author_analysis['Total Number of Contributing Authors'].div(number_xml_docs) , 2)\n",
    "df_author_analysis.loc['Mean'] = df_author_analysis.mean(axis=0).round(2)\n",
    "\n",
    "df_author_analysis.T.to_csv('Figures/RQ5/RQ5__AuthorsStatistics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 54</span></font> Bar chart for new authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": [
     "cell #54"
    ]
   },
   "outputs": [],
   "source": [
    "bar_chart = pygal.Bar(style=custom_style, \n",
    "                      x_title='Years Observed', \n",
    "                      y_title='Total Numbers', \n",
    "                      truncate_legend = -1, \n",
    "                      legend_at_bottom=True, \n",
    "                      print_values=True, \n",
    "                      print_values_position='bottom')\n",
    "bar_chart.title = 'DHd Authors'\n",
    "bar_chart.x_labels = filenames_xml\n",
    "bar_chart.add('All Authors', df_author_analysis.T.iloc[0][:-1])\n",
    "bar_chart.add('New Authors', df_author_analysis.T.iloc[1][:-1])\n",
    "bar_chart.render_to_file('Figures/RQ5/RQ5__ContributorsAnalysis.svg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================================================================\n",
    "\n",
    "==========================================================================================================================\n",
    "\n",
    "=========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 6: Author-Topic Clustering\n",
    "\n",
    "### *Which clusters of researchers can be found with regard to topics and how have the clusters been changing?* "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ6: Functions\n",
    "\n",
    "- Function *get_authors_and_topics*:\n",
    "\n",
    "This function takes two lists and one dictionary as input, as well as the first xml document's index. One list - *authors_no_duplicates* - contains all author names extracted from the xml files and is then sorted alphabetically. The second list *all_author_teams* contains the authors of each text so that it can be determined which text was written by whom. The input dictionary *main_topics* is the one returned by the function *find_document_topics*, which is already applied in RQ1, containing the most prominent topic of each document. These three input variables are used to infer which author has written on which (most salient) topic. This information is stored in the dictionary *authors_and_topics*, where each author name is a key and the values are lists containing the topics an author has written about. \n",
    "In order to make later visualizations more readible and understandable, the data is reduced to authors which have contributed in DHd conferences at least nine times. The reduced dictionary of authors and topics is returned by the function.\n",
    "\n",
    "In this function, only the documents from index 231 on are taken into account. Those documents are the ones springing from xml files where the documents' authors are noted down in the xml markup.\n",
    "\n",
    "- Function *create_vectors*:\n",
    "\n",
    "*create_vectors* takes the dictionary from *get_authors_and_topics* as input and transforms the information on the authors' contributions to topics into a sparse vector representation. Through this, a vector with the length of the final topic number is created for each author (i.e. key of the dictionary), meaning that the vector contains a 0 where the author did not contribute to a topic. For topics the author contributed to, the vector contains an integer how often the author contributed to that topic. \n",
    "The function returns the dictionary with authors (keys) and vectors (values), as well as a list of only the vectors and a list of only the authors' names. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 55</span></font> get_authors_and_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": [
     "cell #55"
    ]
   },
   "outputs": [],
   "source": [
    "def get_authors_and_topics(authors_no_duplicates, all_author_teams, main_topics, index_first_xml_document):\n",
    "    \n",
    "    authors_and_topics = {}\n",
    "    for name in sorted(authors_no_duplicates):\n",
    "        topics_per_author=[]\n",
    "        # setting text_id to 231 (in index_first_xml_document), because only from document 231 on the authors are noted down in markup of xml files\n",
    "        document_id = index_first_xml_document\n",
    "        # iterating over all authors in all texts, trying to find the 'key' currently looked at\n",
    "        for document in all_author_teams:\n",
    "            for author in document:\n",
    "                # if the key matches the author of the text, then note the text id and through that find the salient topic of the text\n",
    "                if name == author:\n",
    "                    document_topic = main_topics[document_id]\n",
    "                    topics_per_author.append(document_topic)\n",
    "                authors_and_topics[name] = topics_per_author \n",
    "            document_id +=1\n",
    "\n",
    "    return authors_and_topics  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 56</span></font> create_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": [
     "cell #56"
    ]
   },
   "outputs": [],
   "source": [
    "def create_vectors(authors_and_topics, minimun_number_of_contributions):\n",
    "\n",
    "    # transforming the data from reduced_authors_and_topics into a vector representation\n",
    "    # advantage: easier to plot and counts how often each topic was written on by the authors\n",
    "    vector = {}\n",
    "    for key in authors_and_topics:\n",
    "        if len(authors_and_topics[key]) > minimun_number_of_contributions:\n",
    "        # creating a vector with a length corresponding to the number of topics\n",
    "            vector[key] = [0]*final_num_topics\n",
    "            for digit in authors_and_topics[key]:\n",
    "                vector[key][digit-1] += 1\n",
    "    # retrieving the author names to use them as labels and the vectors to determine distances between the vectors\n",
    "    only_authors = [key for key in vector]\n",
    "    only_vectors = [vector[key] for key in vector]\n",
    "\n",
    "    return vector, only_vectors, only_authors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ6: Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 57</span></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": [
     "cell #57"
    ]
   },
   "outputs": [],
   "source": [
    "index_first_xml_document = 231\n",
    "\n",
    "# slicing the dict main_topics because for this RQ only the documents froom 2016-2023 are needed beginning with index 231\n",
    "main_topics_xml = dict(itertools.islice(main_topics.items(), index_first_xml_document, len(textnames)))  \n",
    "authors_and_topics = get_authors_and_topics(authors_no_duplicates, all_author_teams, main_topics_xml, index_first_xml_document)\n",
    "vector, only_vectors, only_authors = create_vectors(authors_and_topics, 8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 58</span></font> Creating a dot chart visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": [
     "cell #58"
    ]
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for digit in np.arange(0, 1, 0.5):\n",
    "    # dividing the dictionary into several lists, to make the output plot more readible\n",
    "    part = dict(list(vector.items())[round(len(vector)*digit) : round(len(vector)*(digit+0.5))])\n",
    "\n",
    "    dot_chart = pygal.Dot(human_readable = True, \n",
    "                            width = 800, height= 800, \n",
    "                            truncate_legend = 20,\n",
    "                            truncate_label = -1, \n",
    "                            style = custom_style, \n",
    "                            legend_box_size = 6, \n",
    "                            x_label_rotation= 90)\n",
    "    dot_chart.title = 'Authors with >8 contributions and the topics they wrote about'\n",
    "    dot_chart.x_labels = list(topics.values())\n",
    "\n",
    "    for key in part:\n",
    "        dot_chart.add(key, part[key])\n",
    "\n",
    "    name = 'Figures/RQ6/RQ6__Authors_and_Topics_' + str(i) + '.svg'\n",
    "    dot_chart.render_to_file(name)\n",
    "    i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:violet'><font size='2'>Cell 59</span></font> Creating a dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": [
     "cell #59"
    ]
   },
   "outputs": [],
   "source": [
    "create_dendrogram(only_vectors, \n",
    "                  ' ', \n",
    "                  'Closeness of Authors Calculated by Topic Vectors', \n",
    "                  None, \n",
    "                  only_authors,\n",
    "                  'Figures/RQ6/RQ6__Dendrogram.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet Allocation. *Journal of\n",
    "Machine Learning Research, 3*, 993–1022.\n",
    "\n",
    "Chen, X., Zou, D., Xie, H. (2020). Fifty years of British Journal of Education Technology: A topic modeling based bibliometric perspective. *British Journal of Education Technology, 51*(3), 692-708.\n",
    "\n",
    "Du, K. (2022, March 7). Evaluating Hyperparameter Alpha of LDA Topic Modeling. Zenodo. Digital Humanities im deutschsprachigen Raum 2022. https://doi.org/10.5281/zenodo.6327965\n",
    "\n",
    "geetansh044. (n.d.). *How to Perform a Mann-Kendall Trend Test in Python*. https://www.geeksforgeeks.org/how-to-perform-a-mann-kendall-trend-test-in-python/ (29.09.2023).\n",
    "\n",
    "Kumar, K. (2018). *Evaluation of Topic Modeling: Topic Coherence*. https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/ (29.09.2023).\n",
    "\n",
    "Mann, H. B. (1945). Nonparametric Tests Against Trend. *Econometrica, 13*(3), 245-259. (https://www.jstor.org/stable/1907187).\n",
    "\n",
    "Řehůřek, R. (2022). *LDA model*. https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html (29.09.2023)\n",
    "\n",
    "Řehůřek, R. (2022). *models.ldamodel – Latent Dirichlet Allocation*. https://radimrehurek.com/gensim/models/ldamodel.html (29.09.2023)\n",
    "\n",
    "Röder, M., Both, A., & Hinneburg, A. (2015). Exploring the Space of Topic Coherence\n",
    "Measures. In X. Cheng (Ed.), *ACM Digital Library, Proceedings of the Eighth ACM International\n",
    "Conference on Web Search and Data Mining* (pp. 399–408). ACM. https://doi.org/10.1145/2684822.2685324.\n",
    "\n",
    "Schöch, C. (2017). Topic Modeling Genre: An Exploration of French Classical and Enlightenment\n",
    "Drama. *Digital Humanities Quarterly, 11*(2). http://www.digitalhumanities.org/dhq/vol/11/2/000291/000291.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "265bbd40db63aa34df1bd83f77ecf498882faae903508c6e893ae6addaebaa43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
